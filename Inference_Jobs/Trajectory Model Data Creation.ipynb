{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a7ab838-acd4-4adc-990c-9dbec0d7bf86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from config_infer import InferenceConfig\n",
    "cfg = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09dce32e-e214-4626-8814-eba03d18b3ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "select * from clientstate.full_locations\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "# df.createOrReplaceTempView(\"gps_data\")\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f2ab898-21b9-452a-b7fc-1b49622aed02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "userpiphistory = spark.read.table(\"main_prod.datascience.userpiphistory\")\n",
    "\n",
    "# keep only valid times (optional but wise)\n",
    "userpiphistory = userpiphistory.filter(F.col(\"createdon\").isNotNull())\n",
    "\n",
    "userid_timezone_df = (\n",
    "    userpiphistory.groupBy(\"userid\")\n",
    "      .agg(F.max(F.struct(\"createdon\", \"timezone\")).alias(\"maxrow\"))\n",
    "      .select(\n",
    "          \"userid\",\n",
    "          F.col(\"maxrow.timezone\").alias(\"timezone\"),\n",
    "      )\n",
    ").where(F.col(\"timezone\").isNotNull())\n",
    "\n",
    "display(userid_timezone_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6df18aad-6d0d-41a7-be63-fb79cc39a6b7",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1758559268230}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# remove rows where location_timestamp is within 2 days of the current date\n",
    "\n",
    "df_fil = df.where(\n",
    "  \"to_date(from_unixtime(location_timestamp/1000)) >= date_sub(current_date(), 3) and \" +\n",
    "  \"to_date(from_unixtime(location_timestamp/1000)) < current_date()\"\n",
    ")\n",
    "# display(df_fil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2a39f0a-506d-4ac0-bb06-6d6ca1cacf5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_with_tz = df_fil.join(userid_timezone_df, [\"userid\"], \"inner\")\n",
    "\n",
    "df_with_tz.createOrReplaceTempView(\"df_with_tz\")\n",
    "# display(df_with_tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "049cfb6b-4562-4f73-a030-f2dbe614f250",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "select distinct userid, latitude, longitude, from_utc_timestamp(from_unixtime(location_timestamp / 1000), timezone) AS localized_timestamp, timezone from df_with_tz\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df.createOrReplaceTempView(\"gps_data_loc_ts\")\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfef9ae5-9821-4271-b29a-15d0312b028d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_v2 = df.where(\"latitude is not NULL and longitude is not NULL and localized_timestamp is not NULL and timezone is not NULL\")\n",
    "# display(df_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "254659c6-899f-427c-8213-c79ba67a4ff7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def get_current_date_in_tz(tz):\n",
    "    try:\n",
    "        tz_time = datetime.now(ZoneInfo(tz))\n",
    "        tz_date = tz_time.date()\n",
    "        return tz_date\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "get_current_date_in_tz_udf = udf(get_current_date_in_tz, DateType())\n",
    "\n",
    "df_v3  = df_v2.withColumn(\"current_tz_date\", get_current_date_in_tz_udf(\"timezone\"))\n",
    "# display(df_v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8ea78c5-83e5-49d5-a227-d1f3203c9c87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_v4 = df_v3.where(\"current_tz_date is not NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7dbe5e0-fdc5-492b-8d5a-3d012182aa68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# keep only locations with timestamps in the previous day\n",
    "from datetime import timedelta\n",
    "df_v5 = df_v4.where(\"localized_timestamp >= current_tz_date - interval 1 day and localized_timestamp < current_tz_date\")\n",
    "# display(df_v5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eece14cf-0ae4-4686-b428-c187ed89abbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_v5.createOrReplaceTempView(\"all_traj_data_loc_ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "813d199d-6c79-479e-9d24-bcb2900e9087",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    userid,\n",
    "    DATE(localized_timestamp) AS traj_date,\n",
    "    COLLECT_LIST(localized_timestamp) AS timestamps,\n",
    "    COLLECT_LIST(latitude) AS latitudes,\n",
    "    COLLECT_LIST(longitude) AS longitudes\n",
    "FROM \n",
    "    all_traj_data_loc_ts\n",
    "GROUP BY \n",
    "    userid, DATE(localized_timestamp)\n",
    "ORDER BY \n",
    "    userid, traj_date\n",
    "\"\"\"\n",
    "\n",
    "result_df = spark.sql(query)\n",
    "# display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7b0ee08-ef07-4093-accd-5b94050b27b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StructType, StructField, ArrayType, DoubleType, DateType, TimestampType\n",
    "def sort_by_time(timestamps, longitudes, latitudes):\n",
    "    sorted_ts = []\n",
    "    polylines = []\n",
    "    for ts, lon, lat in sorted(zip(timestamps, longitudes, latitudes), key=lambda x: x[0]):\n",
    "        sorted_ts.append(ts)\n",
    "        polylines.append([float(lon), float(lat)])\n",
    "    return sorted_ts, polylines\n",
    "\n",
    "\n",
    "sort_and_extract_udf = udf(sort_by_time, \n",
    "                           StructType([\n",
    "                               StructField(\"sorted_ts\", ArrayType(TimestampType())),\n",
    "                               StructField(\"polylines\", ArrayType(ArrayType(DoubleType())))\n",
    "                           ]))\n",
    "\n",
    "\n",
    "result_df_v2 = result_df.withColumn(\"sorted_data\", \n",
    "                                         sort_and_extract_udf(\"timestamps\", \"longitudes\", \"latitudes\"))\n",
    "\n",
    "result_df_v2 = result_df_v2.withColumn(\"sorted_ts\", col(\"sorted_data.sorted_ts\")) \\\n",
    "                             .withColumn(\"wgs_seq\", col(\"sorted_data.polylines\")) \\\n",
    "                             .drop(\"sorted_data\")\n",
    "# display(result_df_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cce5683b-0ebe-4df0-a690-4086d6f0db9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_df_v3 = result_df_v2.drop(\"timestamps\", \"longitudes\", \"latitudes\")\n",
    "# display(result_df_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36c43268-a08d-4c36-af77-f1774b3e7598",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, ArrayType, DoubleType, BooleanType\n",
    "from pyspark.sql.functions import udf, col\n",
    "\n",
    "import math\n",
    "def lonlat2meters(lon, lat):\n",
    "    semimajoraxis = 6378137.0\n",
    "    east = lon * 0.017453292519943295\n",
    "    north = lat * 0.017453292519943295\n",
    "    t = math.sin(north)\n",
    "    return semimajoraxis * east, 3189068.5 * math.log((1 + t + 1e-5) / (1 - t + 1e-5))\n",
    "\n",
    "\n",
    "lonlat2meters_udf = udf(lambda traj: [list(lonlat2meters(p[0], p[1])) for p in traj], ArrayType(ArrayType(DoubleType())))\n",
    "result_df_v4 = result_df_v3.withColumn(\"merc_seq\", lonlat2meters_udf(col(\"wgs_seq\")))\n",
    "# display(result_df_v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6a0c286-715d-4360-9d0e-a00f00575011",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def filter_based_on_timestamps(ts_list):\n",
    "    unique_hours = set()\n",
    "    for ts in ts_list:\n",
    "        unique_hours.add(ts.hour)\n",
    "    if len(unique_hours) > 7:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "filter_based_on_timestamps_udf = udf(filter_based_on_timestamps, BooleanType())\n",
    "result_df_v5 = result_df_v4.filter(filter_based_on_timestamps_udf(col(\"sorted_ts\")))\n",
    "# display(result_df_v5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9025a135-a43f-4453-a40b-20aedeebfeac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# result_df_v5.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87c946d5-1555-426a-9fe9-4b639fc5c79b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, ArrayType, DoubleType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "def udf_get_min_max_lat_lon(wgs_seq):\n",
    "    min_lat = 100000\n",
    "    max_lat = -100000\n",
    "    min_lon = 100000\n",
    "    max_lon = -100000\n",
    "\n",
    "    for lon, lat in wgs_seq:\n",
    "        if lat < min_lat:\n",
    "            min_lat = lat\n",
    "        if lat > max_lat:\n",
    "            max_lat = lat\n",
    "        if lon < min_lon:\n",
    "            min_lon = lon\n",
    "        if lon > max_lon:\n",
    "            max_lon = lon\n",
    "    return min_lat, max_lat, min_lon, max_lon\n",
    "\n",
    "get_min_max_lat_lon_udf = udf(udf_get_min_max_lat_lon, StructType([\n",
    "    StructField(\"min_lat\", DoubleType()),\n",
    "    StructField(\"max_lat\", DoubleType()),\n",
    "    StructField(\"min_lon\", DoubleType()),\n",
    "    StructField(\"max_lon\", DoubleType())\n",
    "]))\n",
    "result_df_v6 = result_df_v5.withColumn(\"min_max_lat_lon\", get_min_max_lat_lon_udf(col(\"wgs_seq\")))\n",
    "result_df_v6 = result_df_v6.withColumn(\"min_lat\", col(\"min_max_lat_lon.min_lat\")) \\\n",
    "       .withColumn(\"max_lat\", col(\"min_max_lat_lon.max_lat\")) \\\n",
    "       .withColumn(\"min_lon\", col(\"min_max_lat_lon.min_lon\")) \\\n",
    "       .withColumn(\"max_lon\", col(\"min_max_lat_lon.max_lon\")) \\\n",
    "       .drop(\"min_max_lat_lon\")\n",
    "\n",
    "# display(result_df_v6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1305eda-e7a4-43b5-8617-ff990f4e35ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target_min_lat = 25.11833\n",
    "target_max_lat = 49.38447\n",
    "target_min_lon = -124.73306\n",
    "target_max_lon = -66.94978\n",
    "\n",
    "df_fil = result_df_v6.filter((col(\"min_lat\") >= target_min_lat) & (col(\"max_lat\") <= target_max_lat) & (col(\"min_lon\") >= target_min_lon) & (col(\"max_lon\") <= target_max_lon))\n",
    "# df_fil.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f84ad84e-8752-4041-8e23-bb152faf7ff6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_fil = df_fil.drop(\"min_lat\", \"max_lat\", \"min_lon\", \"max_lon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be90d9cc-d760-489f-99dc-6acf8b6885ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # create empty table in df\n",
    "\n",
    "# schema = StructType([\n",
    "#     StructField(\"userid\", IntegerType(), True),\n",
    "#     StructField(\"traj_date\", DateType(), True),\n",
    "#     StructField(\"sorted_ts\", ArrayType(TimestampType()), True),\n",
    "#     StructField(\"wgs_seq\", ArrayType(ArrayType(DoubleType()))),\n",
    "#     StructField(\"merc_seq\", ArrayType(ArrayType(DoubleType())))\n",
    "# ])\n",
    "\n",
    "# empty_df = spark.createDataFrame([], schema)\n",
    "\n",
    "# empty_df.write.mode(\"overwrite\").saveAsTable(\"main_prod.datascience_scratchpad.traj_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5adf274-2d76-428b-9af7-c0ff93037333",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_fil.createOrReplaceTempView(\"traj_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71133654-ba1e-4dd4-ba31-7d59356d4bbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# MERGE INTO main_prod.ml_data.traj_data AS target\n",
    "# USING traj_data AS source\n",
    "# ON target.userid = source.userid\n",
    "#    AND target.traj_date = source.traj_date\n",
    "# WHEN MATCHED THEN \n",
    "#   UPDATE SET *\n",
    "# WHEN NOT MATCHED THEN\n",
    "#   INSERT *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6709f7ae-1dee-4a38-aff6-e2fff1c1e2d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# write above cell in python\n",
    "\n",
    "spark.sql(\"\"\"merge into {} t\n",
    "using traj_data s\n",
    "on t.userid = s.userid and t.traj_date = s.traj_date\n",
    "when matched then update set *\n",
    "when not matched then insert *\"\"\".format(cfg.traj_df_table_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc1b7ea5-3400-4d8a-a45c-5cb9e2f282fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8862198372597957,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Trajectory Model Data Creation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
