{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../model\")\n",
    "from trajcl import TrajCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Config()\n",
    "\n",
    "conf.dataset = 'nyc'\n",
    "conf.post_value_updates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'porto_20200'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.dataset_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sagemaker-user/TrajCL/data/porto_20200_cell100_cellspace.pkl'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.dataset_cell_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/.conda/envs/trajcl/lib/python3.12/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = TrajCL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.aws.credentials.provider\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/sagemaker-user/.conda/envs/trajcl/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/sagemaker-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/sagemaker-user/.ivy2/jars\n",
      "io.delta#delta-sharing-spark_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-467ad064-395c-4398-9ad9-011748b3d9cc;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-sharing-spark_2.12;3.2.0 in central\n",
      "\tfound io.delta#delta-spark_2.12;3.2.0 in central\n",
      "\tfound io.delta#delta-storage;3.2.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      "\tfound io.delta#delta-sharing-client_2.12;1.0.5 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound commons-logging#commons-logging;1.2 in central\n",
      "\tfound commons-codec#commons-codec;1.11 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.1 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.901 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 327ms :: artifacts dl 14ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.901 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.11 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.2 from central in [default]\n",
      "\tio.delta#delta-sharing-client_2.12;1.0.5 from central in [default]\n",
      "\tio.delta#delta-sharing-spark_2.12;3.2.0 from central in [default]\n",
      "\tio.delta#delta-spark_2.12;3.2.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.2.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   12  |   0   |   0   |   0   ||   12  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-467ad064-395c-4398-9ad9-011748b3d9cc\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 12 already retrieved (0kB/9ms)\n",
      "25/08/07 11:35:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from ah_databricks_data_loader import DatabricksDataLoader\n",
    "\n",
    "# Instantiate the DatabricksDataLoader.\n",
    "ddl = DatabricksDataLoader()\n",
    "\n",
    "# Load data.\n",
    "df = ddl.load_as_spark(schema=\"datascience_scratchpad\", table=\"nyc_train_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "candidate_df = df.filter(col(\"traj_id\").contains(\"4474029_\")).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traj_id</th>\n",
       "      <th>timestamps_filtered</th>\n",
       "      <th>wgs_seq_filtered</th>\n",
       "      <th>merc_seq_filtered</th>\n",
       "      <th>trajlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4474029_2025-02-14</td>\n",
       "      <td>[2025-02-14 04:45:18, 2025-02-14 05:40:37, 202...</td>\n",
       "      <td>[[-74.2201211, 40.842971], [-74.2201674, 40.84...</td>\n",
       "      <td>[[-8262146.0874671005, 4989207.440164468], [-8...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4474029_2019-07-27</td>\n",
       "      <td>[2019-07-27 00:00:19, 2019-07-27 00:12:05, 201...</td>\n",
       "      <td>[[-74.2198396, 40.8427089], [-74.2201477, 40.8...</td>\n",
       "      <td>[[-8262114.751030441, 4989168.872291069], [-82...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4474029_2025-06-01</td>\n",
       "      <td>[2025-06-01 03:37:20, 2025-06-01 07:10:11, 202...</td>\n",
       "      <td>[[-74.219858, 40.8430117], [-74.2200431, 40.84...</td>\n",
       "      <td>[[-8262116.799309071, 4989213.429161161], [-82...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4474029_2020-09-13</td>\n",
       "      <td>[2020-09-13 00:11:59, 2020-09-13 03:28:21, 202...</td>\n",
       "      <td>[[-74.2200829, 40.8430845], [-74.2198778, 40.8...</td>\n",
       "      <td>[[-8262141.835062551, 4989224.141675475], [-82...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4474029_2020-03-12</td>\n",
       "      <td>[2020-03-12 06:57:58, 2020-03-12 07:24:17, 202...</td>\n",
       "      <td>[[-74.2199927, 40.8429431], [-74.2200895, 40.8...</td>\n",
       "      <td>[[-8262131.7940444825, 4989203.334687288], [-8...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              traj_id                                timestamps_filtered  \\\n",
       "0  4474029_2025-02-14  [2025-02-14 04:45:18, 2025-02-14 05:40:37, 202...   \n",
       "1  4474029_2019-07-27  [2019-07-27 00:00:19, 2019-07-27 00:12:05, 201...   \n",
       "2  4474029_2025-06-01  [2025-06-01 03:37:20, 2025-06-01 07:10:11, 202...   \n",
       "3  4474029_2020-09-13  [2020-09-13 00:11:59, 2020-09-13 03:28:21, 202...   \n",
       "4  4474029_2020-03-12  [2020-03-12 06:57:58, 2020-03-12 07:24:17, 202...   \n",
       "\n",
       "                                    wgs_seq_filtered  \\\n",
       "0  [[-74.2201211, 40.842971], [-74.2201674, 40.84...   \n",
       "1  [[-74.2198396, 40.8427089], [-74.2201477, 40.8...   \n",
       "2  [[-74.219858, 40.8430117], [-74.2200431, 40.84...   \n",
       "3  [[-74.2200829, 40.8430845], [-74.2198778, 40.8...   \n",
       "4  [[-74.2199927, 40.8429431], [-74.2200895, 40.8...   \n",
       "\n",
       "                                   merc_seq_filtered  trajlen  \n",
       "0  [[-8262146.0874671005, 4989207.440164468], [-8...       30  \n",
       "1  [[-8262114.751030441, 4989168.872291069], [-82...       88  \n",
       "2  [[-8262116.799309071, 4989213.429161161], [-82...       25  \n",
       "3  [[-8262141.835062551, 4989224.141675475], [-82...       32  \n",
       "4  [[-8262131.7940444825, 4989203.334687288], [-8...       29  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sagemaker-user/TrajCL/data/porto_20200_cell100_cellspace.pkl'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.dataset_cell_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6260/2792526184.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrajCL(\n",
       "  (clmodel): MoCo(\n",
       "    (criterion): CrossEntropyLoss()\n",
       "    (encoder_q): DualSTB(\n",
       "      (pos_encoder): PositionalEncoding(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (structural_attn): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (spatial_attn): SpatialMSM(\n",
       "        (pos_encoder): PositionalEncoding(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (trans_encoder): SpatialMSMEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-2): 3 x SpatialMSMLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (norm1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_k): DualSTB(\n",
       "      (pos_encoder): PositionalEncoding(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (structural_attn): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (spatial_attn): SpatialMSM(\n",
       "        (pos_encoder): PositionalEncoding(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (trans_encoder): SpatialMSMEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-2): 3 x SpatialMSMLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (norm1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mlp_q): Projector(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (mlp_k): Projector(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\")\n",
    "checkpoint_file = \"/home/sagemaker-user/TrajCL/exp/snapshots/nyc_TrajCL_best.pt\"\n",
    "checkpoint = torch.load(checkpoint_file)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/.conda/envs/trajcl/lib/python3.12/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "from utils.traj import *\n",
    "import pickle\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "embs = pickle.load(open(\"/home/sagemaker-user/TrajCL/data/nyc_cell500_embdim256_embs.pkl\", 'rb')).to('cpu').detach() # tensor\n",
    "cellspace = pickle.load(open(\"/home/sagemaker-user/TrajCL/data/nyc_cell500_cellspace.pkl\", 'rb'))\n",
    "\n",
    "def infer(traj):\n",
    "    traj_cell, traj_p = zip(*[merc2cell2(t, cellspace) for t in traj])\n",
    "    traj_emb_p = [torch.tensor(generate_spatial_features(t, cellspace)) for t in traj_p]\n",
    "    traj_emb_p = pad_sequence(traj_emb_p, batch_first = False).to(device)\n",
    "    traj_emb_cell = [embs[list(t)] for t in traj_cell]\n",
    "    traj_emb_cell = pad_sequence(traj_emb_cell, batch_first = False).to(device)\n",
    "    traj_len = torch.tensor(list(map(len, traj_cell)), dtype = torch.long, device = device)\n",
    "    traj_embs = model.interpret(traj_emb_cell.float(), traj_emb_p.float(), traj_len)\n",
    "    return traj_embs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = infer(candidates_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([473, 256])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "# Normalize the rows (L2 normalization)\n",
    "output_normalized = normalize(output.cpu().detach().numpy(), axis=1)\n",
    "\n",
    "# Compute cosine similarity: dot product of normalized vectors\n",
    "similarity_matrix = np.dot(output_normalized, output_normalized.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 33 466 316 412 165]\n",
      " [ 99 245  71 429 333]\n",
      " [158 472 294  91  44]\n",
      " ...\n",
      " [461 435 379 142 271]\n",
      " [400 236 234 297 177]\n",
      " [128 322 172 357 207]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assume similarity_matrix is your m x m cosine similarity matrix\n",
    "# Optional: set diagonal to -inf to ignore self-similarity\n",
    "np.fill_diagonal(similarity_matrix, -np.inf)\n",
    "\n",
    "# Get top 5 similar indices for each row\n",
    "top5_indices = np.argsort(-similarity_matrix, axis=1)[:, :5]\n",
    "\n",
    "print(top5_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  37 441 372 180]\n",
      " [  1 211 162 247 101]\n",
      " [  2 101 173 295  89]\n",
      " ...\n",
      " [470 101 209  22  89]\n",
      " [471 211 101 162 298]\n",
      " [472 295  89 173   4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assume similarity_matrix is your m x m cosine similarity matrix\n",
    "# Optional: set diagonal to -inf to ignore self-similarity\n",
    "np.fill_diagonal(similarity_matrix, -np.inf)\n",
    "\n",
    "# Get top 5 similar indices for each row\n",
    "bottom5_indices = np.argsort(similarity_matrix, axis=1)[:, :5]\n",
    "\n",
    "print(bottom5_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4474029_2025-02-14 :  [('4474029_2025-03-21', 0.951891), ('4474029_2024-12-24', 0.9515693), ('4474029_2024-11-23', 0.9484984), ('4474029_2025-04-09', 0.9475976), ('4474029_2024-12-03', 0.94156325)]\n",
      "4474029_2019-07-27 :  [('4474029_2019-08-04', 0.99469346), ('4474029_2019-11-17', 0.9936477), ('4474029_2019-06-02', 0.99351305), ('4474029_2019-11-19', 0.9921478), ('4474029_2019-06-16', 0.9915563)]\n",
      "4474029_2025-06-01 :  [('4474029_2022-04-23', 0.9245522), ('4474029_2025-02-04', 0.9022228), ('4474029_2022-08-30', 0.90073687), ('4474029_2025-03-08', 0.8958865), ('4474029_2022-09-26', 0.89439297)]\n",
      "4474029_2020-09-13 :  [('4474029_2019-08-31', 0.96266145), ('4474029_2019-11-02', 0.9570831), ('4474029_2025-03-20', 0.9440542), ('4474029_2019-07-21', 0.9371742), ('4474029_2019-08-19', 0.93653125)]\n",
      "4474029_2020-03-12 :  [('4474029_2020-01-03', 0.9304388), ('4474029_2020-03-04', 0.9237604), ('4474029_2020-02-20', 0.914265), ('4474029_2020-03-03', 0.90973747), ('4474029_2020-02-19', 0.8975645)]\n",
      "4474029_2024-09-12 :  [('4474029_2025-02-04', 0.92794), ('4474029_2024-09-10', 0.92784363), ('4474029_2025-03-27', 0.9208729), ('4474029_2025-04-08', 0.9036455), ('4474029_2025-06-10', 0.9030632)]\n",
      "4474029_2020-02-25 :  [('4474029_2020-02-28', 0.8895231), ('4474029_2020-02-14', 0.8872555), ('4474029_2020-01-31', 0.8849437), ('4474029_2020-01-02', 0.872265), ('4474029_2020-03-10', 0.85215974)]\n",
      "4474029_2023-04-10 :  [('4474029_2021-08-24', 0.98416984), ('4474029_2023-11-10', 0.9832459), ('4474029_2023-10-24', 0.9812181), ('4474029_2024-04-19', 0.98084754), ('4474029_2023-07-18', 0.9791171)]\n",
      "4474029_2019-11-30 :  [('4474029_2022-08-19', 0.9874428), ('4474029_2023-11-10', 0.98119295), ('4474029_2025-07-02', 0.9769108), ('4474029_2021-08-24', 0.97653496), ('4474029_2024-10-18', 0.9751928)]\n",
      "4474029_2019-08-13 :  [('4474029_2019-11-20', 0.95340943), ('4474029_2019-08-26', 0.9388866), ('4474029_2019-08-05', 0.9368712), ('4474029_2019-11-15', 0.928626), ('4474029_2019-08-01', 0.9179549)]\n"
     ]
    }
   ],
   "source": [
    "# similar trajactories\n",
    "traj_id_list = list(candidate_df['traj_id'])\n",
    "for i in range(10):\n",
    "    print(\"{} : \".format(traj_id_list[i]), [(traj_id_list[x], similarity_matrix[i][x]) for x in top5_indices[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4474029_2025-02-14 :  [('4474029_2025-02-14', -inf), ('4474029_2020-11-01', -0.01639717), ('4474029_2020-02-11', 0.015235383), ('4474029_2019-12-20', 0.01625728), ('4474029_2020-02-07', 0.021524005)]\n",
      "4474029_2019-07-27 :  [('4474029_2019-07-27', -inf), ('4474029_2020-11-28', -0.033838633), ('4474029_2023-10-21', -0.020210706), ('4474029_2023-08-27', 0.01195579), ('4474029_2020-01-09', 0.01954792)]\n",
      "4474029_2025-06-01 :  [('4474029_2025-06-01', -inf), ('4474029_2020-01-09', -0.00023288565), ('4474029_2020-03-03', 0.044660028), ('4474029_2020-02-05', 0.060766675), ('4474029_2019-12-16', 0.06908514)]\n",
      "4474029_2020-09-13 :  [('4474029_2020-09-13', -inf), ('4474029_2020-11-28', -0.05460479), ('4474029_2020-01-09', -0.04002695), ('4474029_2020-02-07', -0.024458436), ('4474029_2020-01-17', -0.0017153919)]\n",
      "4474029_2020-03-12 :  [('4474029_2020-03-12', -inf), ('4474029_2020-01-20', -0.1571126), ('4474029_2025-07-05', -0.13545239), ('4474029_2022-06-12', -0.12833218), ('4474029_2023-10-14', -0.12110312)]\n",
      "4474029_2024-09-12 :  [('4474029_2024-09-12', -inf), ('4474029_2020-02-05', -0.014496408), ('4474029_2020-03-03', 0.043496564), ('4474029_2020-03-12', 0.059246674), ('4474029_2019-12-16', 0.061347187)]\n",
      "4474029_2020-02-25 :  [('4474029_2020-02-25', -inf), ('4474029_2020-01-20', -0.045066617), ('4474029_2023-08-27', -0.02531167), ('4474029_2024-04-13', -0.018088987), ('4474029_2025-07-05', -0.014196165)]\n",
      "4474029_2023-04-10 :  [('4474029_2023-04-10', -inf), ('4474029_2020-02-05', -0.03025442), ('4474029_2020-03-12', -0.022456033), ('4474029_2020-03-04', 0.0022129656), ('4474029_2020-01-10', 0.007709623)]\n",
      "4474029_2019-11-30 :  [('4474029_2019-11-30', -inf), ('4474029_2020-02-05', -0.028206488), ('4474029_2020-03-12', -0.02048911), ('4474029_2020-03-04', -0.0014396189), ('4474029_2020-03-03', 0.016481288)]\n",
      "4474029_2019-08-13 :  [('4474029_2019-08-13', -inf), ('4474029_2023-08-27', 0.019607645), ('4474029_2023-10-21', 0.021212552), ('4474029_2020-01-20', 0.037379418), ('4474029_2023-10-14', 0.088579185)]\n"
     ]
    }
   ],
   "source": [
    "# similar trajactories\n",
    "traj_id_list = list(candidate_df['traj_id'])\n",
    "for i in range(10):\n",
    "    print(\"{} : \".format(traj_id_list[i]), [(traj_id_list[x], similarity_matrix[i][x]) for x in bottom5_indices[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trajcl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
