{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../model\")\n",
    "from trajcl import TrajCL\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Config()\n",
    "\n",
    "conf.dataset = 'generic_v3'\n",
    "conf.post_value_updates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/.conda/envs/trajcl/lib/python3.12/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = TrajCL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrajCL(\n",
       "  (clmodel): MoCo(\n",
       "    (criterion): CrossEntropyLoss()\n",
       "    (encoder_q): DualSTB(\n",
       "      (pos_encoder): PositionalEncoding(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (structural_attn): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (spatial_attn): SpatialMSM(\n",
       "        (pos_encoder): PositionalEncoding(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (trans_encoder): SpatialMSMEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-2): 3 x SpatialMSMLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (norm1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_k): DualSTB(\n",
       "      (pos_encoder): PositionalEncoding(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (structural_attn): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (spatial_attn): SpatialMSM(\n",
       "        (pos_encoder): PositionalEncoding(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (trans_encoder): SpatialMSMEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-2): 3 x SpatialMSMLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (norm1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mlp_q): Projector(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (mlp_k): Projector(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.aws.credentials.provider\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/sagemaker-user/.conda/envs/trajcl/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/sagemaker-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/sagemaker-user/.ivy2/jars\n",
      "io.delta#delta-sharing-spark_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-363156ba-5b88-47d0-814a-700990d74c79;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-sharing-spark_2.12;3.2.0 in central\n",
      "\tfound io.delta#delta-spark_2.12;3.2.0 in central\n",
      "\tfound io.delta#delta-storage;3.2.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      "\tfound io.delta#delta-sharing-client_2.12;1.0.5 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound commons-logging#commons-logging;1.2 in central\n",
      "\tfound commons-codec#commons-codec;1.11 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.1 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.901 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 357ms :: artifacts dl 18ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.901 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.11 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.2 from central in [default]\n",
      "\tio.delta#delta-sharing-client_2.12;1.0.5 from central in [default]\n",
      "\tio.delta#delta-sharing-spark_2.12;3.2.0 from central in [default]\n",
      "\tio.delta#delta-spark_2.12;3.2.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.2.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   12  |   0   |   0   |   0   ||   12  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-363156ba-5b88-47d0-814a-700990d74c79\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 12 already retrieved (0kB/9ms)\n",
      "25/09/08 18:25:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# from ah_databricks_data_loader import DatabricksDataLoader\n",
    "\n",
    "# # Instantiate the DatabricksDataLoader.\n",
    "# ddl = DatabricksDataLoader()\n",
    "\n",
    "# # Load data.\n",
    "# test_df_1 = ddl.load_as_spark(schema=\"datascience_scratchpad\", table=\"la_traj_data_v9_part1\")\n",
    "# test_df_2 = ddl.load_as_spark(schema=\"datascience_scratchpad\", table=\"la_traj_data_v9_part2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df= test_df_1.join(test_df_2, on  = ['userid','traj_date'])\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import udf, col\n",
    "# from pyspark.sql.types import StructType, StructField, ArrayType, DoubleType, DateType, TimestampType, IntegerType\n",
    "# def get_weekday(traj_date):\n",
    "#     return traj_date.weekday()\n",
    "\n",
    "# import math\n",
    "# def lonlat2meters(lon, lat):\n",
    "#     semimajoraxis = 6378137.0\n",
    "#     east = lon * 0.017453292519943295\n",
    "#     north = lat * 0.017453292519943295\n",
    "#     t = math.sin(north)\n",
    "#     return semimajoraxis * east, 3189068.5 * math.log((1 + t) / (1 - t))\n",
    "    \n",
    "# get_weekday_udf = udf(lambda traj_date: get_weekday(traj_date), IntegerType())\n",
    "# test_df = test_df.withColumn(\"weekday\", get_weekday_udf(col(\"traj_date\")))\n",
    "# lonlat2meters_udf = udf(lambda traj: [list(lonlat2meters(p[0], p[1])) for p in traj], ArrayType(ArrayType(DoubleType())))\n",
    "# test_df = test_df.withColumn(\"merc_seq\", lonlat2meters_udf(col(\"polylines_final\")))\n",
    "# display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.write.mode(\"overwrite\").parquet(\"/home/sagemaker-user/TrajCL/data/la/la_subset_1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in repartitioned files: 39735\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "parquet_files = glob(\"/home/sagemaker-user/TrajCL/data/la/la_subset_1k/*.parquet\")\n",
    "total_count = 0\n",
    "df_list = []\n",
    "for file in parquet_files:\n",
    "    df = pd.read_parquet(file)\n",
    "    df_list.append(df)\n",
    "    total_count += len(df)\n",
    "\n",
    "\n",
    "print(f\"Total records in repartitioned files: {total_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>traj_date</th>\n",
       "      <th>timestamps</th>\n",
       "      <th>polylines_final</th>\n",
       "      <th>employername</th>\n",
       "      <th>partition_id</th>\n",
       "      <th>pck_0_1</th>\n",
       "      <th>weekday</th>\n",
       "      <th>merc_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2844305</td>\n",
       "      <td>2025-06-24</td>\n",
       "      <td>[2025-06-24T05:49:28.000000000, 2025-06-24T07:...</td>\n",
       "      <td>[[-118.39117477618277, 33.92325761467734], [-1...</td>\n",
       "      <td>Camping World/Gander Outdoors</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-13179245.29050212, 4018502.0477052485], [-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2869661</td>\n",
       "      <td>2024-09-21</td>\n",
       "      <td>[2024-09-21T08:54:19.000000000, 2024-09-21T11:...</td>\n",
       "      <td>[[-118.59423330634597, 34.1905517578125], [-11...</td>\n",
       "      <td>County Of Riverside</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[-13201849.662681118, 4054417.2603058773], [-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2869661</td>\n",
       "      <td>2024-09-22</td>\n",
       "      <td>[2024-09-22T07:02:57.000000000, 2024-09-22T11:...</td>\n",
       "      <td>[[-118.5940859861017, 34.190643310546875], [-1...</td>\n",
       "      <td>County Of Riverside</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[[-13201833.263066543, 4054429.58131514], [-13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2869661</td>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>[2025-02-08T10:03:51.000000000, 2025-02-08T10:...</td>\n",
       "      <td>[[-117.66765060248021, 34.03045269170906], [-1...</td>\n",
       "      <td>County Of Riverside</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[-13098702.947908927, 4032891.811937815], [-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2869661</td>\n",
       "      <td>2025-04-26</td>\n",
       "      <td>[2025-04-26T09:22:08.000000000, 2025-04-26T09:...</td>\n",
       "      <td>[[-117.73360870444878, 34.025118917335035], [-...</td>\n",
       "      <td>County Of Riverside</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[-13106045.37023376, 4032175.3819222637], [-1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userid   traj_date                                         timestamps  \\\n",
       "0  2844305  2025-06-24  [2025-06-24T05:49:28.000000000, 2025-06-24T07:...   \n",
       "1  2869661  2024-09-21  [2024-09-21T08:54:19.000000000, 2024-09-21T11:...   \n",
       "2  2869661  2024-09-22  [2024-09-22T07:02:57.000000000, 2024-09-22T11:...   \n",
       "3  2869661  2025-02-08  [2025-02-08T10:03:51.000000000, 2025-02-08T10:...   \n",
       "4  2869661  2025-04-26  [2025-04-26T09:22:08.000000000, 2025-04-26T09:...   \n",
       "\n",
       "                                     polylines_final  \\\n",
       "0  [[-118.39117477618277, 33.92325761467734], [-1...   \n",
       "1  [[-118.59423330634597, 34.1905517578125], [-11...   \n",
       "2  [[-118.5940859861017, 34.190643310546875], [-1...   \n",
       "3  [[-117.66765060248021, 34.03045269170906], [-1...   \n",
       "4  [[-117.73360870444878, 34.025118917335035], [-...   \n",
       "\n",
       "                    employername  partition_id  pck_0_1  weekday  \\\n",
       "0  Camping World/Gander Outdoors             2        1        1   \n",
       "1            County Of Riverside             0        1        5   \n",
       "2            County Of Riverside             0        1        6   \n",
       "3            County Of Riverside             1        1        5   \n",
       "4            County Of Riverside             1        1        5   \n",
       "\n",
       "                                            merc_seq  \n",
       "0  [[-13179245.29050212, 4018502.0477052485], [-1...  \n",
       "1  [[-13201849.662681118, 4054417.2603058773], [-...  \n",
       "2  [[-13201833.263066543, 4054429.58131514], [-13...  \n",
       "3  [[-13098702.947908927, 4032891.811937815], [-1...  \n",
       "4  [[-13106045.37023376, 4032175.3819222637], [-1...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# test_df = pd.read_parquet(\"/home/sagemaker-user/TrajCL/data/parquet_files/test/nyc_df_v3_with_time/traj_test_df_v3_with_ts.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# userids = test_df['userid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6392/1038578970.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrajCL(\n",
       "  (clmodel): MoCo(\n",
       "    (criterion): CrossEntropyLoss()\n",
       "    (encoder_q): DualSTB(\n",
       "      (pos_encoder): PositionalEncoding(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (structural_attn): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (spatial_attn): SpatialMSM(\n",
       "        (pos_encoder): PositionalEncoding(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (trans_encoder): SpatialMSMEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-2): 3 x SpatialMSMLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (norm1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_k): DualSTB(\n",
       "      (pos_encoder): PositionalEncoding(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (structural_attn): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (spatial_attn): SpatialMSM(\n",
       "        (pos_encoder): PositionalEncoding(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (trans_encoder): SpatialMSMEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-2): 3 x SpatialMSMLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (norm1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mlp_q): Projector(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (mlp_k): Projector(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\")\n",
    "checkpoint_file = \"/home/sagemaker-user/TrajCL/exp/generic_v3/generic_v3_TrajCL_best.pt\"\n",
    "checkpoint = torch.load(checkpoint_file)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/.conda/envs/trajcl/lib/python3.12/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "from utils.traj import *\n",
    "import pickle\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "embs = pickle.load(open(\"/home/sagemaker-user/TrajCL/data/generic_v3_cell250_embdim256_embs.pkl\", 'rb')).to('cpu').detach() # tensor\n",
    "cellspace = pickle.load(open(\"/home/sagemaker-user/TrajCL/data/generic_v3_cell250_cellspace.pkl\", 'rb'))\n",
    "\n",
    "max_batch_size = 512\n",
    "def infer_batch(traj):\n",
    "    traj_cell, traj_p = zip(*[merc2cell2(t, cellspace) for t in traj])\n",
    "    # print(traj_cell)\n",
    "    traj_emb_p = [torch.tensor(generate_spatial_features(t, cellspace)) for t in traj_p]\n",
    "    traj_emb_p = pad_sequence(traj_emb_p, batch_first = False).to(device)\n",
    "    traj_emb_cell = [embs[list(t)] for t in traj_cell]\n",
    "    traj_emb_cell = pad_sequence(traj_emb_cell, batch_first = False).to(device)\n",
    "    traj_len = torch.tensor(list(map(len, traj_cell)), dtype = torch.long, device = device)\n",
    "    # time_indices = pad_sequence([torch.tensor(t, dtype=torch.long) for t in time_indices], batch_first=False, padding_value=-1).to(Config.device)\n",
    "    # print(traj_emb_cell, traj_emb_p, traj_len)\n",
    "    traj_embs = model.interpret(traj_emb_cell.float(), traj_emb_p.float(), traj_len, None)\n",
    "    return traj_embs\n",
    "\n",
    "def infer(traj):\n",
    "    if len(traj)> max_batch_size:\n",
    "        traj_embs = []\n",
    "        for i in range(0, len(traj), max_batch_size):\n",
    "            traj_batch = traj[i:i+max_batch_size]\n",
    "            # time_indices_batch = time_indices[i:i+max_batch_size] \n",
    "            traj_embs.append(infer_batch(traj_batch))\n",
    "        return torch.cat(traj_embs, dim=0)\n",
    "    else:\n",
    "        return infer_batch(traj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique userids: 1000\n",
      "Total unique employernames: 1007\n"
     ]
    }
   ],
   "source": [
    "unique_userids = pd.concat([df['userid'] for df in df_list]).unique()\n",
    "print(f\"Total unique userids: {len(unique_userids)}\")\n",
    "\n",
    "unique_employernames = pd.concat([df['employername'] for df in df_list]).unique()\n",
    "print(f\"Total unique employernames: {len(unique_employernames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_userid(userid):\n",
    "    df_user = pd.concat([df[df['userid']==userid] for df in df_list]).reset_index(drop=True)\n",
    "    return df_user\n",
    "\n",
    "def get_data_for_employername(df_user, employername):\n",
    "    df_emp = df_user[df_user['employername']==employername].reset_index(drop=True)\n",
    "    return df_emp\n",
    "\n",
    "\n",
    "def get_data_for_partition(df_emp, partition):\n",
    "    df_part = df_emp[df_emp['partition_id']==partition].reset_index(drop=True)\n",
    "    df_part = df_part[~df_part['weekday'].isin([5, 6])].reset_index(drop=True) # filter out weekends\n",
    "    df_part = df_part[df_part['pck_0_1']>0].reset_index(drop=True) # filter out zero paycheck amount\n",
    "    return df_part\n",
    "\n",
    "\n",
    "def get_traj_and_time_data(df_part):\n",
    "    traj = df_part['merc_seq'].values\n",
    "    # time_indices = df_part['time_index_list'].values\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dbscan(embs, target_min_similarity=0.85):\n",
    "    from sklearn.cluster import DBSCAN     # require >= 0.9 cosine similarity\n",
    "    eps = 1.0 - target_min_similarity    # cosine distance threshold\n",
    "    n_embs = embs.shape[0]\n",
    "    db = DBSCAN(eps=eps, min_samples=max(int(n_embs*0.3), 5), metric=\"cosine\", n_jobs=-1).fit(embs)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max_xy(traj):\n",
    "    min_x = min([p[0] for p in traj])\n",
    "    max_x = max([p[0] for p in traj])\n",
    "    min_y = min([p[1] for p in traj])\n",
    "    max_y = max([p[1] for p in traj])\n",
    "    return min_x, max_x, min_y, max_y\n",
    "\n",
    "def calculate_dx_dy(k, target_min_x, target_min_y, min_x, max_x, min_y, max_y):\n",
    "    dx = target_min_x+ (k - max_x - min_x) / 2\n",
    "    dy = target_min_y+ (k - max_y - min_y) / 2\n",
    "    return dx, dy\n",
    "\n",
    "def transform_traj(traj, dx, dy):\n",
    "    new_traj = [[p[0] + dx, p[1] + dy] for p in traj]\n",
    "    return new_traj\n",
    "\n",
    "def normalize(trajs, cellspace):\n",
    "    # trajs: list of [[lon, lat], [,], ...]\n",
    "\n",
    "    # 1. augment the input traj in order to form 2 augmented traj views\n",
    "    # 2. convert augmented trajs to the trajs based on mercator space by cells\n",
    "    # 3. read cell embeddings and form batch tensors (sort, pad)\n",
    "\n",
    "    trajs1, trajs2 = [], []\n",
    "    time_indices1, time_indices2 = [], []\n",
    "    final_min_x = 1000000000\n",
    "    final_min_y = 1000000000\n",
    "    final_max_x = -1000000000\n",
    "    final_max_y = -1000000000\n",
    "    max_len_meters = min(cellspace.x_max-cellspace.x_min, cellspace.y_max-cellspace.y_min)\n",
    "    indices_to_omit = []\n",
    "    for i, l in enumerate(trajs):\n",
    "        min_x, max_x, min_y, max_y = get_min_max_xy(l)\n",
    "        # if final_max_x - min_x> max_len_meters or final_max_y-min_y> max_len_meters or max_x - final_min_x> max_len_meters or max_y - final_min_y> max_len_meters or max_x-min_x> max_len_meters or max_y-min_y> max_len_meters:\n",
    "        #     indices_to_omit.append(i)\n",
    "        #     continue\n",
    "        final_min_x = min(final_min_x, min_x)\n",
    "        final_min_y = min(final_min_y, min_y)\n",
    "        final_max_x = max(final_max_x, max_x)\n",
    "        final_max_y = max(final_max_y, max_y)\n",
    "    \n",
    "    if max(final_max_x-final_min_x, final_max_y-final_min_y)>max_len_meters:\n",
    "        # print(max(final_max_x-final_min_x, final_max_y-final_min_y), max_len_meters)\n",
    "        return None\n",
    "    dx, dy = calculate_dx_dy(max_len_meters, cellspace.x_min, cellspace.y_min, final_min_x, final_max_x, final_min_y, final_max_y)\n",
    "    # print(final_min_x, final_max_x, final_min_y, final_max_y)\n",
    "    # print(dx, dy)\n",
    "    for i,l in enumerate(trajs):\n",
    "        if i in indices_to_omit:\n",
    "            continue\n",
    "        new_l = transform_traj(l, dx, dy)\n",
    "        trajs1.append(new_l)\n",
    "    return trajs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:21<00:00, 46.96it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "model.eval()\n",
    "output_dict = {}\n",
    "\n",
    "# 0: moving, 1: static, 2: not enough data\n",
    "def get_gt_and_pred_label(userid):\n",
    "    count = 0\n",
    "    user_data = get_data_for_userid(userid)\n",
    "    employers = user_data['employername'].unique()\n",
    "    for employer in employers:\n",
    "        emp_data = get_data_for_employername(user_data, employer)\n",
    "        partitions = emp_data['partition_id'].unique()\n",
    "        for partition in partitions:\n",
    "            # print(userid, employer, partition)\n",
    "            part_data = get_data_for_partition(emp_data, partition)\n",
    "            if len(part_data)<15:\n",
    "                continue\n",
    "            else:\n",
    "                # print(userid, employer, partition)\n",
    "                # print(len(part_data))\n",
    "                traj = get_traj_and_time_data(part_data)\n",
    "                traj = normalize(traj, cellspace)\n",
    "                # print(traj)\n",
    "                if traj==None:\n",
    "                    count+=1\n",
    "                    pred_label = 3\n",
    "                else:\n",
    "                    embs = infer(traj).detach().cpu().numpy()\n",
    "                    db_scan = apply_dbscan(embs, target_min_similarity=0.85)\n",
    "                    labels = db_scan.labels_                      # shape: (n_samples,)\n",
    "                    cluster_ids = [c for c in np.unique(labels) if c != -1]\n",
    "                    if len(cluster_ids)>0:\n",
    "                        pred_label = 1\n",
    "                    else:\n",
    "                        pred_label = 0\n",
    "                output_dict[(userid, employer, partition)] = pred_label\n",
    "\n",
    "    return count\n",
    "    # if sum(test_data['paycheck_amount'].values) > 0:\n",
    "    #     gt_label = 1\n",
    "    # else:\n",
    "    #     gt_label = 0\n",
    "    # pred_label = 0\n",
    "    # for i in range(len(test_embs)):\n",
    "    #     test_vector = test_embs[i].unsqueeze(0)\n",
    "    #     similarity = cosine_similarity(test_vector.numpy(), train_embs)[0]\n",
    "    #     top_3_indices = np.argsort(similarity)[-3:][::-1]\n",
    "    #     # print(i, top_3_indices)\n",
    "    #     similarity = similarity[top_3_indices]\n",
    "    #     # print(f\"User: {userid}, Test Trajectory {test_data['traj_id'].values[i]}, Top 3 Train Trajectories: {train_data['traj_id'].values[top_3_indices]}, similarity: {similarity}, PCK Amount: {train_data['paycheck_amount'].values[top_3_indices]}\")\n",
    "    #     for sim, idx in zip(similarity, top_3_indices):\n",
    "    #         if sim>0.85 and train_data['paycheck_amount'].values[idx]>0:\n",
    "    #             pred_label = 1\n",
    "    #             break\n",
    "    # return gt_label, pred_label\n",
    "count=0\n",
    "for userid in tqdm(unique_userids):\n",
    "    count+=get_gt_and_pred_label(userid)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output_dict\n",
    "pickle.dump(output_dict, open(\"/home/sagemaker-user/TrajCL/exp/generic_v3/la_subset_output_dict.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(13697306, 'Maxim Healthcare Services', 1): 0,\n",
       " (13532874, 'Confie/freeway insurance', 0): 0,\n",
       " (5584592, 'Newportcare medical group', 1): 1,\n",
       " (3664893, 'Abbott', 0): 1,\n",
       " (6334226, 'rosintechnologies', 0): 3,\n",
       " (9093953, 'PepsiCo', 1): 0,\n",
       " (13867356, 'lake park communities', 0): 0,\n",
       " (13399849, 'Marriott international', 0): 0,\n",
       " (13399849, 'Marriott international', 1): 0,\n",
       " (9210700, 'Walt Disney PA', 0): 1,\n",
       " (9377174, 'COUNTY HEALTH SERVICES', 0): 0,\n",
       " (9377174, 'Maxim healthcare', 0): 0,\n",
       " (2157516, 'Amazon', 0): 3,\n",
       " (14203499, 'Curcuit services llc', 0): 1,\n",
       " (14203499, 'Industrial electronic engineers', 0): 0,\n",
       " (14475344, 'SCHARP', 0): 1,\n",
       " (10658382, '76 Gas', 0): 1,\n",
       " (15705160, 'QVC Distribution Center', 0): 0,\n",
       " (3898274, 'Kiva sales and services', 0): 1,\n",
       " (7209893, 'relativity space', 0): 0,\n",
       " (7209893, 'relativity space', 1): 0,\n",
       " (12192241, \"BJ'S RESTA\", 0): 1,\n",
       " (15933208, 'The gill corporation', 1): 1,\n",
       " (13342539, 'City of Los Angeles', 0): 3,\n",
       " (16690599, 'Colodro-garo llc', 0): 0,\n",
       " (16690599, 'Colodro-garo llc', 1): 0,\n",
       " (14359486, 'huntintong hospital', 0): 3,\n",
       " (14359486, 'huntintong hospital', 1): 3,\n",
       " (4833188, 'Target', 0): 3,\n",
       " (4833188, 'Target', 1): 0,\n",
       " (18617609, 'The Walt Disney Company', 0): 1,\n",
       " (6714853, 'Bank of America', 0): 1,\n",
       " (6714853, 'Bank of America', 1): 0,\n",
       " (1265903, 'Kaiser Permanente', 0): 1,\n",
       " (1265903, 'Kaiser Permanente', 1): 1,\n",
       " (9861781, 'Stuart m gold MD Inc', 0): 1,\n",
       " (9861781, 'Stuart m gold MD Inc', 1): 1,\n",
       " (9910913, 'Ralphs', 0): 3,\n",
       " (9910913, 'Ralphs', 1): 0,\n",
       " (19023671, 'Boys and Girls Club of America ', 1): 1,\n",
       " (19023671, 'United Parcel ', 0): 1,\n",
       " (15459006, 'Level One Security', 0): 1,\n",
       " (3042189, 'Best Contracting Services, Inc', 0): 3,\n",
       " (16262154, 'Alcoa traffic control', 0): 3,\n",
       " (16304961, 'Tarzana smile center', 0): 0,\n",
       " (16304961, 'Tarzana smile center', 1): 0,\n",
       " (14832670, 'Ramo Law PC', 0): 1,\n",
       " (14832670, 'Ramo Law PC', 1): 1,\n",
       " (15853638, 'City of Redondo Beach', 0): 0,\n",
       " (1941727, 'People space', 0): 3,\n",
       " (4926021, 'National water services', 0): 3,\n",
       " (4926021, 'National water services', 1): 3,\n",
       " (4927471, 'Wss ', 0): 1,\n",
       " (11920009, 'GameStop', 0): 0,\n",
       " (10859441, \"CHOC Children's Hospital of Orange County\", 0): 0,\n",
       " (10859441, \"CHOC Children's Hospital of Orange County\", 1): 3,\n",
       " (10886550, 'erecording partners network', 0): 0,\n",
       " (1434270, 'kaiser aluminum', 0): 1,\n",
       " (1434270, 'kaiser aluminum', 1): 1,\n",
       " (16408948, 'Hub group trucking', 0): 0,\n",
       " (16408948, 'Hub group trucking', 1): 0,\n",
       " (18349433, 'Alex Gladkov', 0): 1,\n",
       " (18349433, 'Alex Gladkov', 1): 1,\n",
       " (7309578, 'AAA TLC Healthcare', 0): 0,\n",
       " (7309578, 'Vons', 0): 0,\n",
       " (5856845, 'A&I Transport', 0): 3,\n",
       " (14045006, 'Brewster nutrition\\n', 0): 3,\n",
       " (14045006, 'Brewster nutrition\\n', 1): 3,\n",
       " (12449047, 'Allied Universal Security Services', 1): 1,\n",
       " (12449047, 'Allied Universal Security Services', 2): 1,\n",
       " (17141362, 'University of California', 0): 1,\n",
       " (17141362, 'Hoag urgent care', 0): 0,\n",
       " (14081255, 'BANK OF AMERICA,', 0): 3,\n",
       " (14106533, 'Walgreens', 0): 0,\n",
       " (9265352, 'city of bakersfield ', 1): 3,\n",
       " (12270524, 'The Public Health Company', 0): 0,\n",
       " (12270524, 'Los Angeles County -  Public Health', 0): 0,\n",
       " (4047020, 'Walt Disney Parks and Resorts', 0): 1,\n",
       " (1354196, 'University of California Irvine', 0): 1,\n",
       " (1354196, 'University of California Irvine', 1): 1,\n",
       " (14744389, 'Public Storage', 0): 0,\n",
       " (13446398, 'BBSI', 0): 0,\n",
       " (934088, 'Aventura at the bay', 0): 1,\n",
       " (1017886, 'BizzellUS ', 0): 1,\n",
       " (1026864, 'markman and Wolstan', 1): 0,\n",
       " (7037317, 'Anaheim arena management ', 0): 0,\n",
       " (7037317, 'Anaheim arena management ', 1): 0,\n",
       " (17403020, 'Marvin engineering', 0): 0,\n",
       " (17403020, 'Marvin engineering', 1): 3,\n",
       " (8584582, 'Los angeles county department of mental health', 0): 1,\n",
       " (8584582, 'Los angeles county department of mental health', 1): 0,\n",
       " (2745231, 'Ivy of seal beach', 0): 1,\n",
       " (2756784, 'Alderlaw', 0): 3,\n",
       " (2776202, 'CBRE, Inc.', 0): 3,\n",
       " (2776202, 'CBRE, Inc.', 1): 3,\n",
       " (1505814, 'Personal Involvement Center', 0): 0,\n",
       " (1505814, 'Personal Involvement Center', 1): 0,\n",
       " (1570311, 'AlliedBarton Security Services', 0): 1,\n",
       " (1570311, 'AlliedBarton Security Services', 1): 0,\n",
       " (1570311, 'Allied Universal ', 0): 0,\n",
       " (6923192, 'Reel Fathers Rights, APC', 0): 0,\n",
       " (7021548, 'Children hospital los angeles', 0): 1,\n",
       " (7021548, 'PIH Health Hospi', 0): 1,\n",
       " (16566118, 'Condor Corporation', 0): 0,\n",
       " (16566118, 'B&G Millworks', 0): 0,\n",
       " (16210476, 'Commerce casino', 0): 1,\n",
       " (16210476, 'Commerce casino', 1): 0,\n",
       " (16210476, 'California Comme', 0): 0,\n",
       " (15052445, 'Glidewell Laboratories ', 0): 1,\n",
       " (13970365, 'platinum group security', 0): 0,\n",
       " (13970365, 'Ontario high school', 0): 3,\n",
       " (8264804, 'Dcx chol', 0): 1,\n",
       " (8264804, 'Dcx chol', 1): 1,\n",
       " (14891340, 'ralphs supermarket', 0): 1,\n",
       " (11819053, 'Adventist health white memorial', 0): 1,\n",
       " (11869137, 'HRC Fertility', 1): 0,\n",
       " (6741267, 'All Pure Pool & Spa Inc. ', 0): 0,\n",
       " (6741432, 'Developmental Pathways', 0): 0,\n",
       " (6741432, 'Developmental Pathways', 1): 0,\n",
       " (5710705, 'Rush Enterprises Inc', 0): 1,\n",
       " (5710705, 'Rush Enterprises Inc', 1): 0,\n",
       " (3425027, 'Long beach memorial medical center', 0): 0,\n",
       " (3454391, 'CHARTER COMMUNICATIONS', 0): 0,\n",
       " (5173182, 'South Bay workforce Investment ', 0): 1,\n",
       " (5212119, 'La County Probation Dept ', 0): 0,\n",
       " (13500485, 'OC hand surgery specialist', 0): 3,\n",
       " (4471891, 'Optimal hospice', 1): 0,\n",
       " (4493299, 'midway car rental', 1): 3,\n",
       " (7749365, 'The Private Suite', 0): 1,\n",
       " (7749365, 'The Private Suite', 1): 3,\n",
       " (7749365, 'THE PRIVATE SUIT', 0): 1,\n",
       " (5459286, 'providence holy cross', 0): 0,\n",
       " (5459286, 'providence holy cross', 1): 0,\n",
       " (1665725, 'Aptive Enviromental', 0): 3,\n",
       " (20408598, 'Laboratory Corpo', 0): 0,\n",
       " (20408598, 'ubereats driver', 0): 1,\n",
       " (20487160, 'Irvine BMW', 0): 0,\n",
       " (20487160, 'Irvine BMW', 1): 1,\n",
       " (2386554, 'Longwood management ', 0): 1,\n",
       " (11683175, 'Anheuser-Busch', 0): 1,\n",
       " (11683175, 'Anheuser-Busch', 1): 3,\n",
       " (11683175, 'ANHEUSER-BUSCH C', 0): 1,\n",
       " (11718861, 'folks ', 0): 0,\n",
       " (11718861, 'folks ', 1): 0,\n",
       " (5047449, 'SD&A Teleservices', 0): 1,\n",
       " (5047449, 'SD&A Teleservices', 1): 1,\n",
       " (5095247, 'KinderCare', 0): 1,\n",
       " (5095247, 'KinderCare', 1): 0,\n",
       " (5142564, \"Trader Joe's\", 1): 0,\n",
       " (14537378, 'UPS', 0): 1,\n",
       " (14537378, 'UPS', 1): 3,\n",
       " (14537378, 'OH SO ORIGINAL,', 0): 1,\n",
       " (16597132, 'LA County ', 0): 1,\n",
       " (16624800, 'Union Pacific Railroad', 0): 3,\n",
       " (16624800, 'Union Pacific Railroad', 1): 3,\n",
       " (16655618, 'Velocity Clinical Research', 0): 1,\n",
       " (16655618, 'Home guardian angel', 0): 1,\n",
       " (3545062, \"Trader Joe's\", 0): 0,\n",
       " (3545062, \"Trader Joe's\", 1): 0,\n",
       " (3545062, 'Imak Distribution ', 0): 0,\n",
       " (2470544, 'optum rx', 0): 1,\n",
       " (2470544, 'optum rx', 1): 1,\n",
       " (2584720, 'The Home Depot', 0): 1,\n",
       " (2584720, 'The Home Depot', 1): 1,\n",
       " (2584720, 'Home Depot U.S.A ', 0): 1,\n",
       " (17058132, 'Jacks candy', 0): 3,\n",
       " (17058132, 'Jacks candy', 1): 3,\n",
       " (17058132, 'Jacks candy', 2): 3,\n",
       " (13719802, 'Universal Studios Hollywood', 0): 1,\n",
       " (13752751, 'Felix Lighting', 0): 1,\n",
       " (13752751, 'Felix Lighting', 1): 1,\n",
       " (20995182, 'Inclusive links', 0): 0,\n",
       " (21037378, 'Alliance Technical Group', 0): 1,\n",
       " (21037378, 'Alliance Technical Group', 1): 1,\n",
       " (11535139, 'Behr ', 0): 1,\n",
       " (11535139, 'Behr ', 1): 1,\n",
       " (11577666, 'university of southern california', 0): 0,\n",
       " (11577666, 'university of southern california', 1): 0,\n",
       " (5330328, 'Olive Garden', 0): 1,\n",
       " (5330328, 'Olive Garden', 1): 1,\n",
       " (5382957, 'One main financial', 0): 1,\n",
       " (9701913, 'wesley health center', 0): 0,\n",
       " (9701913, 'wesley health center', 1): 0,\n",
       " (9753998, 'Organic By Nature Inc.', 0): 1,\n",
       " (9753998, 'Organic By Nature Inc.', 1): 1,\n",
       " (9781117, 'Dresser-Rand', 0): 0,\n",
       " (15077935, \"Carter's Oshkosh \", 0): 1,\n",
       " (15077935, \"Carter's Oshkosh \", 1): 0,\n",
       " (15101406, 'costco wholesale', 0): 0,\n",
       " (4746778, 'Via care community health center', 0): 0,\n",
       " (4746778, 'Via care community health center', 1): 3,\n",
       " (18332105, 'Big league plumbing', 0): 0,\n",
       " (18332105, 'Big league plumbing', 1): 0,\n",
       " (12841045, 'Megamex Foods, LLC', 0): 1,\n",
       " (12871480, 'loews hotels', 0): 0,\n",
       " (12871480, 'loews hotels', 1): 3,\n",
       " (17548812, 'Valvoline', 0): 0,\n",
       " (17548812, 'Valvoline', 1): 1,\n",
       " (12984979, 'Home Depot', 0): 0,\n",
       " (12984979, 'Home Depot', 1): 1,\n",
       " (13006071, 'Ihss provider', 1): 0,\n",
       " (13034865, 'AEG Presents', 0): 1,\n",
       " (13034865, 'AEG Presents', 1): 1,\n",
       " (86813, 'Peraton', 0): 1,\n",
       " (98630, 'AOO Events', 0): 0,\n",
       " (98630, 'AOO Events', 1): 1,\n",
       " (6021527, 'Block, inc', 0): 0,\n",
       " (6021527, 'Walt Disney PA', 0): 0,\n",
       " (6099818, 'Square Inc', 1): 1,\n",
       " (7465540, 'CVS Pharmacy', 0): 1,\n",
       " (7465540, 'CVS Pharmacy', 1): 1,\n",
       " (7465540, 'CVS', 0): 1,\n",
       " (17922218, 'Homebase', 0): 1,\n",
       " (1145581, 'undercar plus', 0): 0,\n",
       " (1145581, 'undercar plus', 1): 1,\n",
       " (19658075, '2R drilling ', 0): 3,\n",
       " (19727695, 'PacWest Security Services', 0): 1,\n",
       " (19749809, 'Universal Studios Hollywood', 0): 1,\n",
       " (19789436, 'Carrara treatment wellness & spa', 0): 1,\n",
       " (19789436, 'Southern California Hospital at culver Ciy', 0): 1,\n",
       " (19789436, 'Southern California Hospital at culver Ciy', 1): 0,\n",
       " (17221982, 'Ford Motor Company', 0): 3,\n",
       " (17221982, 'Get Spiffy', 0): 3,\n",
       " (17259840, 'ventura foods llc', 0): 1,\n",
       " (17259840, 'ventura foods llc', 1): 1,\n",
       " (17262305, 'Great Maple', 0): 0,\n",
       " (17262305, 'Hilton', 0): 0,\n",
       " (17287263, 'California credit union', 0): 1,\n",
       " (19058750, 'VACP TREAS 310', 0): 0,\n",
       " (19143768, 'Ramsey entertainment security ', 0): 1,\n",
       " (19147844, 'Mendocino Farms', 1): 0,\n",
       " (19193876, 'Kaiser permenante ', 0): 0,\n",
       " (19193876, 'Kaiser permenante ', 1): 0,\n",
       " (15621092, '13048736', 0): 1,\n",
       " (15621092, '13048736', 1): 0,\n",
       " (15626619, 'one electric llc', 0): 1,\n",
       " (15657800, 'ITC Service Group ', 0): 0,\n",
       " (15657800, 'ITC Service Group ', 1): 0,\n",
       " (4273208, 'California tools and welding supplies', 0): 3,\n",
       " (15169271, 'Moss & company', 0): 0,\n",
       " (15169271, 'Moss & company', 1): 3,\n",
       " (15193813, 'Disneyland Resort ', 0): 0,\n",
       " (15193813, 'Disneyland Resort ', 1): 3,\n",
       " (15193813, 'Walt Disney PA', 0): 0,\n",
       " (21419773, 'Sofitel Hotel', 0): 1,\n",
       " (21447699, 'Og nation', 0): 0,\n",
       " (21496258, 'Chipotle', 0): 3,\n",
       " (21600597, 'Macys Retail Hol', 0): 1,\n",
       " (21686958, 'South shore deli provisions inc', 0): 3,\n",
       " (11257281, 'LA Philarmonic Association ', 0): 0,\n",
       " (11257281, 'LA Philarmonic Association ', 1): 0,\n",
       " (17712419, 'IHSS2 ST OF CA IHSSMIPSE', 0): 1,\n",
       " (17712419, 'IHSS2 ST OF CA IHSSMIPSE', 1): 1,\n",
       " (17712419, 'IHSS2 ST OF CA IHSSMIPSE', 2): 0,\n",
       " (15514663, 'rang technologies', 0): 0,\n",
       " (15514663, 'IHSS In Home Support Services', 0): 0,\n",
       " (15521045, 'Drain Rooter Plumbing', 0): 3,\n",
       " (15521045, 'Drain Rooter Plumbing', 1): 0,\n",
       " (7607194, 'ADP Totalsource Direct Deposit', 0): 0,\n",
       " (7607194, 'ADP Totalsource Direct Deposit', 1): 0,\n",
       " (2593434, 'Sada Systems', 0): 1,\n",
       " (2622885, 'Sonder', 0): 3,\n",
       " (2622885, 'Sonder', 1): 3,\n",
       " (2622885, 'Sonder Usa Inc.', 0): 1,\n",
       " (7296833, 'Fanduel', 0): 1,\n",
       " (7296833, 'Fanduel', 1): 1,\n",
       " (7296833, 'Fanduel', 2): 1,\n",
       " (18849499, 'Home Depot', 0): 1,\n",
       " (18849499, 'Home Depot', 1): 1,\n",
       " (20246405, 'UCLA housing and hospitality', 0): 1,\n",
       " (20263221, 'Los Angeles General Hospital', 0): 0,\n",
       " (20265931, 'staples distribution center', 0): 1,\n",
       " (20265931, 'staples distribution center', 1): 0,\n",
       " (11504879, 'Impulse space', 0): 0,\n",
       " (11528026, 'gate gourmet ', 0): 1,\n",
       " (11528026, 'gate gourmet ', 1): 1,\n",
       " (11528026, 'Gate gourmet inc ', 0): 1,\n",
       " (19545998, 'katsu-ya', 0): 1,\n",
       " (19545998, 'katsu-ya', 1): 1,\n",
       " (19564799, 'Amazon Delivery Driver/De', 0): 1,\n",
       " (10304662, 'Lobel Financial', 0): 0,\n",
       " (10304662, 'DCS Courier Services', 0): 3,\n",
       " (10403185, 'FDC management', 0): 0,\n",
       " (10421439, 'san Francisco veterans affairs medical center ', 0): 1,\n",
       " (10421439, 'san Francisco veterans affairs medical center ', 1): 1,\n",
       " (7846220, 'Hertz Rent-A-Car', 0): 1,\n",
       " (7846220, 'Hertz Rent-A-Car', 1): 1,\n",
       " (13057528, 'Glass america ', 0): 3,\n",
       " (13057528, 'Glass america ', 1): 0,\n",
       " (13064691, 'Home Depot', 0): 3,\n",
       " (13080638, 'San Gabriel Pomona Regional Center', 0): 1,\n",
       " (13080638, 'Horizon Personnel Services', 0): 1,\n",
       " (18639380, 'Panera Bread', 0): 1,\n",
       " (18663704, 'Chernin Entertainment', 0): 1,\n",
       " (18732965, 'supercare health', 0): 1,\n",
       " (18746501, 'prismatik', 0): 1,\n",
       " (18746501, 'prismatik', 1): 1,\n",
       " (18756781, 'Chase', 0): 0,\n",
       " (462801, 'westrock', 0): 1,\n",
       " (462801, 'westrock', 1): 1,\n",
       " (462801, 'WESTROCK SERVICE', 0): 1,\n",
       " (500725, 'Davita Healthcare Partners', 0): 0,\n",
       " (500725, 'OPTUM CARE, INC.', 0): 0,\n",
       " (18112161, 'Albertsons', 0): 1,\n",
       " (18112161, 'Albertsons', 1): 0,\n",
       " (18140879, 'Vector marketing', 0): 0,\n",
       " (18197417, 'Nastec International', 0): 1,\n",
       " (6456612, 'Lalgbt center', 0): 3,\n",
       " (6456612, 'Lalgbt center', 1): 0,\n",
       " (6465096, 'Stoneledge Furniture ', 1): 0,\n",
       " (14610836, 'Raytheon Technologies', 0): 3,\n",
       " (14610836, 'Raytheon Technologies', 1): 1,\n",
       " (14620881, 'County of los angeles', 0): 0,\n",
       " (14620881, 'County of los angeles', 1): 1,\n",
       " (19990462, 'Mta metro (Lacmta)', 0): 1,\n",
       " (19990462, 'Mta metro (Lacmta)', 1): 1,\n",
       " (19990462, 'Lacmta', 0): 1,\n",
       " (20017680, 'Forever 21', 0): 1,\n",
       " (20017680, 'Forever 21', 1): 1,\n",
       " (20033050, 'Los Angeles Lax Marriott ', 0): 0,\n",
       " (20044352, 'Auto Service Center', 0): 1,\n",
       " (19213166, 'GUSTO PAY', 0): 1,\n",
       " (19257895, 'IHSS', 0): 3,\n",
       " (19257895, 'IHSS', 1): 1,\n",
       " (19257895, 'THE HERTZ CORPOR', 0): 1,\n",
       " (19286728, 'Maverick Aerospace, LLC', 0): 1,\n",
       " (20579239, 'Cali Clouds Smoke & Vape Shop', 0): 1,\n",
       " (20720591, 'Fpi', 0): 1,\n",
       " (20728200, 'Platinum Security', 0): 0,\n",
       " (20728200, 'Platinum Security', 1): 0,\n",
       " (20728200, 'PLATINUM SECURIT', 0): 0,\n",
       " (14664380, 'Bhh Respite Services', 0): 0,\n",
       " (14696703, 'The hoxton', 0): 0,\n",
       " (14699196, 'Fedex Office', 0): 0,\n",
       " (14723072, 'Lindsey manufacturing', 0): 1,\n",
       " (14723072, 'Lindsey manufacturing', 1): 1,\n",
       " (14723072, 'Lindsey manufacturing', 2): 1,\n",
       " (14726986, 'SVF flow controls', 0): 1,\n",
       " (14726986, 'SVF flow controls', 1): 1,\n",
       " (6120399, 'costco wholesale', 0): 0,\n",
       " (6120399, 'costco wholesale', 1): 3,\n",
       " (6123748, \"knott's berry farm\", 0): 3,\n",
       " (6149935, 'mission home care', 0): 1,\n",
       " (6149935, 'mission home care', 1): 1,\n",
       " (18016188, 'Matrix Surfaces', 0): 3,\n",
       " (18016188, 'Matrix Surfaces', 1): 3,\n",
       " (18064340, 'Blick Art Materials', 0): 1,\n",
       " (18064340, 'Animal Urgent Care', 0): 3,\n",
       " (18073172, 'Casa de Cadillac', 0): 1,\n",
       " (18073172, 'Casa de Cadillac', 1): 1,\n",
       " (22185920, 'Home Depot U.S.A ', 0): 1,\n",
       " (22208718, 'City of Los Angeles', 0): 1,\n",
       " (22307209, 'KINDREDHEALTHCAR', 0): 1,\n",
       " (22330965, 'Walmart', 0): 1,\n",
       " (22349572, 'Marugame Udon ', 0): 1,\n",
       " (22395177, 'CSL Behring,-OSV', 0): 1,\n",
       " (22567694, 'SoCal ship services ', 0): 0,\n",
       " (22572120, 'Marriott international', 0): 1,\n",
       " (22584238, 'davita', 0): 1,\n",
       " (22629034, 'Empire workforce solutions', 0): 1,\n",
       " (258550, 'Regal Entertainment Group', 0): 1,\n",
       " (258550, 'Regal Entertainment Group', 1): 1,\n",
       " (258550, 'REGAL CINEMAS IN', 0): 1,\n",
       " (308966, 'Whole Foods Market', 0): 0,\n",
       " (308966, 'Whole Foods Market', 1): 0,\n",
       " (308966, 'Lazy Acres Natural Market', 0): 0,\n",
       " (319003, 'Evço Plastics', 0): 1,\n",
       " (319003, 'Evço Plastics', 1): 0,\n",
       " (19838236, 'Areas USA', 0): 1,\n",
       " (19838236, 'Areas USA', 1): 1,\n",
       " (19838236, 'Tower EV LLC ', 0): 1,\n",
       " (19938037, 'Anillo Industries', 0): 1,\n",
       " (19938037, 'Anillo Industries', 1): 1,\n",
       " (19959410, 'Orkin Pest Control - Rollins', 0): 3,\n",
       " (19959410, 'Orkin Pest Control - Rollins', 1): 1,\n",
       " (19959410, 'Rollins Inc', 0): 0,\n",
       " (2895591, 'CVS Pharmacy', 0): 1,\n",
       " (2895591, 'CVS Pharmacy', 1): 1,\n",
       " (2895591, 'CVS', 0): 1,\n",
       " (19407902, 'northrop grumman', 0): 1,\n",
       " (19407902, 'northrop grumman', 1): 1,\n",
       " (19433549, 'Aerotek temp agency', 0): 1,\n",
       " (19433549, 'Aerotek temp agency', 1): 3,\n",
       " (19433549, 'Aerotek, Inc.', 0): 1,\n",
       " (19440985, 'International Paper ', 0): 0,\n",
       " (19468934, 'ADP Transport LLC', 0): 3,\n",
       " (865083, 'American  golf corporation', 0): 3,\n",
       " (865083, 'American  golf corporation', 1): 3,\n",
       " (871623, 'd and e homes', 0): 1,\n",
       " (871623, 'd and e homes', 1): 0,\n",
       " (21109121, 'Advocate for peace and urban unity', 0): 1,\n",
       " (21109121, 'Advocate for peace and urban unity', 1): 1,\n",
       " (21220194, 'Spectrum charter', 0): 1,\n",
       " (21220194, 'Spectrum charter', 1): 1,\n",
       " (21228790, 'ucla ronald reagan hospital ', 0): 1,\n",
       " (21283896, 'Ghirardelli Associates Inc', 0): 0,\n",
       " (21318766, 'agri treas 310', 0): 0,\n",
       " (21352209, 'Hawaiian Airlines', 0): 3,\n",
       " (21777941, 'Mv transportation', 0): 3,\n",
       " (21825758, 'Uber', 0): 0,\n",
       " (21883567, 'TALENTBURST-OSV', 0): 0,\n",
       " (21975718, 'ABM', 0): 1,\n",
       " (22126915, 'Icon solutions llc ', 0): 3,\n",
       " (10907900, 'superior grocers ', 0): 1,\n",
       " (10907900, 'superior grocers ', 1): 1,\n",
       " (10907900, 'SUPER CENTER CON', 0): 1,\n",
       " (10997633, 'Joanna vargas salon ', 0): 0,\n",
       " (10997633, 'Joanna vargas salon ', 1): 0,\n",
       " (2032205, 'USPS', 0): 0,\n",
       " (2032205, 'USPS', 1): 1,\n",
       " (2032205, 'USPS', 2): 1,\n",
       " (2048321, 'GrubHub', 0): 1,\n",
       " (16815681, 'prime communications', 0): 1,\n",
       " (16851380, 'dcfs los county', 0): 0,\n",
       " (16851380, 'dcfs los county', 1): 0,\n",
       " (14131584, 'Greenleaf heating and ac', 0): 3,\n",
       " (14131584, 'Greenleaf heating and ac', 1): 3,\n",
       " (14153346, 'Marten transportation', 0): 3,\n",
       " (14153346, 'Marten transportation', 1): 3,\n",
       " (14165741, 'GUSTOPAY 076962', 0): 0,\n",
       " (8324278, 'Home Comfort USA', 0): 3,\n",
       " (8324278, 'Home Comfort USA', 1): 1,\n",
       " (8328508, 'Military', 1): 1,\n",
       " (8383355, 'northeast valley health corporation ', 0): 0,\n",
       " (8383355, 'northeast valley health corporation ', 1): 0,\n",
       " (8396837, 'concentra urgent care ', 0): 0,\n",
       " (15374424, 'Los Angeles County Department of Public Social Services ', 0): 1,\n",
       " (15374424, 'Los Angeles County Department of Public Social Services ', 1): 1,\n",
       " (3702276, 'City of Pasadena ', 0): 0,\n",
       " (3721419, \"Fleming's Prime Steakhouse & Wine Bar \", 0): 1,\n",
       " (3721419, \"Fleming's Prime Steakhouse & Wine Bar \", 1): 0,\n",
       " (3745794, 'Conexus Recruiting', 0): 0,\n",
       " (17464944, 'AZUSA UNIFIED SCHOOL DISTRICT', 0): 1,\n",
       " (17464944, 'AZUSA UNIFIED SCHOOL DISTRICT', 1): 1,\n",
       " (17515089, 'Smokin Barrel', 0): 0,\n",
       " (8081558, 'Securitas Security Services ', 0): 1,\n",
       " (8081558, 'Securitas Security Services ', 1): 1,\n",
       " (8081558, 'Securitas USA, I', 0): 1,\n",
       " (10183280, 'Partners Personnel', 0): 1,\n",
       " (10208317, 'Kirkhill, Inc. ', 0): 0,\n",
       " (10215705, 'Kaiser Permanente', 0): 0,\n",
       " (10215705, 'Kaiser Permanente', 1): 1,\n",
       " (10215705, 'KAISER FOUNDATIO ', 0): 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 159, 1: 213, 3: 71}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_dict = {}\n",
    "for k,v in output_dict.items():\n",
    "    if v in count_dict:\n",
    "        count_dict[v]+=1\n",
    "    else:\n",
    "        count_dict[v]=1\n",
    "count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_userid_employer_partition(userid, employer, partition):\n",
    "    df_user = pd.concat([df[df['userid']==userid] for df in df_list]).reset_index(drop=True)\n",
    "    df_emp = df_user[df_user['employername']==employer].reset_index(drop=True)\n",
    "    df_part = df_emp[df_emp['partition_id']==partition].reset_index(drop=True)\n",
    "    df_part_fil = df_part[~df_part['weekday'].isin([5, 6])].reset_index(drop=True) # filter out weekends\n",
    "    df_part_fil = df_part_fil[df_part_fil['pck_0_1']>0].reset_index(drop=True) # filter out zero paycheck amount\n",
    "    return df_part_fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>traj_date</th>\n",
       "      <th>timestamps</th>\n",
       "      <th>polylines_final</th>\n",
       "      <th>employername</th>\n",
       "      <th>partition_id</th>\n",
       "      <th>pck_0_1</th>\n",
       "      <th>weekday</th>\n",
       "      <th>merc_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-09-13</td>\n",
       "      <td>[2024-09-13T00:01:18.000000000, 2024-09-13T00:...</td>\n",
       "      <td>[[-117.90738870397912, 33.796112060546875], [-...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[-13125390.471291533, 4001457.603220949], [-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-09-17</td>\n",
       "      <td>[2024-09-17T07:58:12.000000000, 2024-09-17T09:...</td>\n",
       "      <td>[[-118.03179962477296, 33.762420654296875], [-...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-13139239.831643425, 3996945.362223349], [-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-09-27</td>\n",
       "      <td>[2024-09-27T00:05:10.000000000, 2024-09-27T00:...</td>\n",
       "      <td>[[-117.90710993162298, 33.789398193359375], [-...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[-13125359.438494798, 4000558.283135984], [-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>[2024-10-01T00:02:08.000000000, 2024-10-01T00:...</td>\n",
       "      <td>[[-117.96021522802127, 33.76605224609375], [-1...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-13131271.093048282, 3997431.650700413], [-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-10-03</td>\n",
       "      <td>[2024-10-03T00:04:21.000000000, 2024-10-03T00:...</td>\n",
       "      <td>[[-117.90616567586581, 33.7864990234375], [-11...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[-13125254.32442473, 4000169.962172818], [-13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-10-10</td>\n",
       "      <td>[2024-10-10T00:40:29.000000000, 2024-10-10T00:...</td>\n",
       "      <td>[[-117.8360366482587, 33.724395751953125], [-1...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[-13117447.59678168, 3991854.87243622], [-131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-10-11</td>\n",
       "      <td>[2024-10-11T00:41:21.000000000, 2024-10-11T00:...</td>\n",
       "      <td>[[-117.83387856677241, 33.740478515625], [-117...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[-13117207.360249538, 3994007.637273137], [-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-10-16</td>\n",
       "      <td>[2024-10-16T00:40:38.000000000, 2024-10-16T00:...</td>\n",
       "      <td>[[-117.8335061461756, 33.7332763671875], [-117...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[-13117165.902578339, 3993043.5408923957], [-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-10-21</td>\n",
       "      <td>[2024-10-21T07:31:55.000000000, 2024-10-21T07:...</td>\n",
       "      <td>[[-118.01692226155897, 33.75799560546875], [-1...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-13137583.691146096, 3996352.8536919793], [-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-10-29</td>\n",
       "      <td>[2024-10-29T08:00:26.000000000, 2024-10-29T08:...</td>\n",
       "      <td>[[-118.0282841845051, 33.758880615234375], [-1...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-13138848.494622892, 3996471.3529512724], [-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>[2024-11-04T06:34:16.000000000, 2024-11-04T07:...</td>\n",
       "      <td>[[-118.03181522716046, 33.76245148963731], [-1...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-13139241.568493256, 3996949.4911443796], [-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>[2024-12-03T01:03:07.000000000, 2024-12-03T01:...</td>\n",
       "      <td>[[-117.83529246223165, 33.734146464144025], [-...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-13117364.754372094, 3993160.009801426], [-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>[2024-12-04T01:11:24.000000000, 2024-12-04T01:...</td>\n",
       "      <td>[[-117.83868376380023, 33.74424762042376], [-1...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[-13117742.272335837, 3994512.2106935824], [-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-12-10</td>\n",
       "      <td>[2024-12-10T00:57:09.000000000, 2024-12-10T01:...</td>\n",
       "      <td>[[-117.83878035879904, 33.72138831382513], [-1...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-13117753.025241917, 3991452.3553620195], [-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-12-13</td>\n",
       "      <td>[2024-12-13T00:03:32.000000000, 2024-12-13T00:...</td>\n",
       "      <td>[[-117.91062663567008, 33.796154814110935], [-...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[-13125750.916198593, 4001463.3302714145], [-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-12-16</td>\n",
       "      <td>[2024-12-16T07:29:07.000000000, 2024-12-16T07:...</td>\n",
       "      <td>[[-118.02356183654778, 33.759699653946605], [-...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-13138322.805252934, 3996581.020041055], [-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-12-18</td>\n",
       "      <td>[2024-12-18T00:38:46.000000000, 2024-12-18T00:...</td>\n",
       "      <td>[[-117.83557546788451, 33.72507617181235], [-1...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[-13117396.258417262, 3991945.942138386], [-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-12-19</td>\n",
       "      <td>[2024-12-19T00:05:29.000000000, 2024-12-19T00:...</td>\n",
       "      <td>[[-117.9063792222492, 33.79634815131476], [-11...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[-13125278.096299391, 4001489.228777759], [-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3664893</td>\n",
       "      <td>2024-12-20</td>\n",
       "      <td>[2024-12-20T00:08:18.000000000, 2024-12-20T00:...</td>\n",
       "      <td>[[-117.90627166244558, 33.795925170242796], [-...</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[-13125266.122796822, 4001432.568377874], [-1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userid   traj_date                                         timestamps  \\\n",
       "0   3664893  2024-09-13  [2024-09-13T00:01:18.000000000, 2024-09-13T00:...   \n",
       "1   3664893  2024-09-17  [2024-09-17T07:58:12.000000000, 2024-09-17T09:...   \n",
       "2   3664893  2024-09-27  [2024-09-27T00:05:10.000000000, 2024-09-27T00:...   \n",
       "3   3664893  2024-10-01  [2024-10-01T00:02:08.000000000, 2024-10-01T00:...   \n",
       "4   3664893  2024-10-03  [2024-10-03T00:04:21.000000000, 2024-10-03T00:...   \n",
       "5   3664893  2024-10-10  [2024-10-10T00:40:29.000000000, 2024-10-10T00:...   \n",
       "6   3664893  2024-10-11  [2024-10-11T00:41:21.000000000, 2024-10-11T00:...   \n",
       "7   3664893  2024-10-16  [2024-10-16T00:40:38.000000000, 2024-10-16T00:...   \n",
       "8   3664893  2024-10-21  [2024-10-21T07:31:55.000000000, 2024-10-21T07:...   \n",
       "9   3664893  2024-10-29  [2024-10-29T08:00:26.000000000, 2024-10-29T08:...   \n",
       "10  3664893  2024-11-04  [2024-11-04T06:34:16.000000000, 2024-11-04T07:...   \n",
       "11  3664893  2024-12-03  [2024-12-03T01:03:07.000000000, 2024-12-03T01:...   \n",
       "12  3664893  2024-12-04  [2024-12-04T01:11:24.000000000, 2024-12-04T01:...   \n",
       "13  3664893  2024-12-10  [2024-12-10T00:57:09.000000000, 2024-12-10T01:...   \n",
       "14  3664893  2024-12-13  [2024-12-13T00:03:32.000000000, 2024-12-13T00:...   \n",
       "15  3664893  2024-12-16  [2024-12-16T07:29:07.000000000, 2024-12-16T07:...   \n",
       "16  3664893  2024-12-18  [2024-12-18T00:38:46.000000000, 2024-12-18T00:...   \n",
       "17  3664893  2024-12-19  [2024-12-19T00:05:29.000000000, 2024-12-19T00:...   \n",
       "18  3664893  2024-12-20  [2024-12-20T00:08:18.000000000, 2024-12-20T00:...   \n",
       "\n",
       "                                      polylines_final employername  \\\n",
       "0   [[-117.90738870397912, 33.796112060546875], [-...       Abbott   \n",
       "1   [[-118.03179962477296, 33.762420654296875], [-...       Abbott   \n",
       "2   [[-117.90710993162298, 33.789398193359375], [-...       Abbott   \n",
       "3   [[-117.96021522802127, 33.76605224609375], [-1...       Abbott   \n",
       "4   [[-117.90616567586581, 33.7864990234375], [-11...       Abbott   \n",
       "5   [[-117.8360366482587, 33.724395751953125], [-1...       Abbott   \n",
       "6   [[-117.83387856677241, 33.740478515625], [-117...       Abbott   \n",
       "7   [[-117.8335061461756, 33.7332763671875], [-117...       Abbott   \n",
       "8   [[-118.01692226155897, 33.75799560546875], [-1...       Abbott   \n",
       "9   [[-118.0282841845051, 33.758880615234375], [-1...       Abbott   \n",
       "10  [[-118.03181522716046, 33.76245148963731], [-1...       Abbott   \n",
       "11  [[-117.83529246223165, 33.734146464144025], [-...       Abbott   \n",
       "12  [[-117.83868376380023, 33.74424762042376], [-1...       Abbott   \n",
       "13  [[-117.83878035879904, 33.72138831382513], [-1...       Abbott   \n",
       "14  [[-117.91062663567008, 33.796154814110935], [-...       Abbott   \n",
       "15  [[-118.02356183654778, 33.759699653946605], [-...       Abbott   \n",
       "16  [[-117.83557546788451, 33.72507617181235], [-1...       Abbott   \n",
       "17  [[-117.9063792222492, 33.79634815131476], [-11...       Abbott   \n",
       "18  [[-117.90627166244558, 33.795925170242796], [-...       Abbott   \n",
       "\n",
       "    partition_id  pck_0_1  weekday  \\\n",
       "0              0        1        4   \n",
       "1              0        1        1   \n",
       "2              0        1        4   \n",
       "3              0        1        1   \n",
       "4              0        1        3   \n",
       "5              0        1        3   \n",
       "6              0        1        4   \n",
       "7              0        1        2   \n",
       "8              0        1        0   \n",
       "9              0        1        1   \n",
       "10             0        1        0   \n",
       "11             0        1        1   \n",
       "12             0        1        2   \n",
       "13             0        1        1   \n",
       "14             0        1        4   \n",
       "15             0        1        0   \n",
       "16             0        1        2   \n",
       "17             0        1        3   \n",
       "18             0        1        4   \n",
       "\n",
       "                                             merc_seq  \n",
       "0   [[-13125390.471291533, 4001457.603220949], [-1...  \n",
       "1   [[-13139239.831643425, 3996945.362223349], [-1...  \n",
       "2   [[-13125359.438494798, 4000558.283135984], [-1...  \n",
       "3   [[-13131271.093048282, 3997431.650700413], [-1...  \n",
       "4   [[-13125254.32442473, 4000169.962172818], [-13...  \n",
       "5   [[-13117447.59678168, 3991854.87243622], [-131...  \n",
       "6   [[-13117207.360249538, 3994007.637273137], [-1...  \n",
       "7   [[-13117165.902578339, 3993043.5408923957], [-...  \n",
       "8   [[-13137583.691146096, 3996352.8536919793], [-...  \n",
       "9   [[-13138848.494622892, 3996471.3529512724], [-...  \n",
       "10  [[-13139241.568493256, 3996949.4911443796], [-...  \n",
       "11  [[-13117364.754372094, 3993160.009801426], [-1...  \n",
       "12  [[-13117742.272335837, 3994512.2106935824], [-...  \n",
       "13  [[-13117753.025241917, 3991452.3553620195], [-...  \n",
       "14  [[-13125750.916198593, 4001463.3302714145], [-...  \n",
       "15  [[-13138322.805252934, 3996581.020041055], [-1...  \n",
       "16  [[-13117396.258417262, 3991945.942138386], [-1...  \n",
       "17  [[-13125278.096299391, 4001489.228777759], [-1...  \n",
       "18  [[-13125266.122796822, 4001432.568377874], [-1...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part = get_data_userid_employer_partition(3664893, 'Abbott', 0)\n",
    "df_part.sort_values('traj_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity_matrix(X, eps=1e-8, dtype=np.float32):\n",
    "    X = np.asarray(X, dtype=dtype)\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    Xn = X / np.maximum(norms, eps)\n",
    "    return Xn @ Xn.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(part_df):\n",
    "    traj_dates = list(part_df['traj_date'])\n",
    "    traj = get_traj_and_time_data(part_df)\n",
    "    traj = normalize(traj, cellspace)\n",
    "    embs = infer(traj).detach().cpu().numpy()\n",
    "    similarity = cosine_similarity_matrix(embs)\n",
    "\n",
    "    return similarity, traj\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m df_fil= df_part[df_part[\u001b[33m'\u001b[39m\u001b[33mtraj_date\u001b[39m\u001b[33m'\u001b[39m].isin([datetime.date(\u001b[32m2025\u001b[39m,\u001b[32m3\u001b[39m,\u001b[32m28\u001b[39m), datetime.date(\u001b[32m2025\u001b[39m,\u001b[32m3\u001b[39m,\u001b[32m27\u001b[39m)])]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m sim, traj = \u001b[43mget_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_fil\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mget_similarity\u001b[39m\u001b[34m(part_df)\u001b[39m\n\u001b[32m      3\u001b[39m traj = get_traj_and_time_data(part_df)\n\u001b[32m      4\u001b[39m traj = normalize(traj, cellspace)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m embs = \u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraj\u001b[49m\u001b[43m)\u001b[49m.detach().cpu().numpy()\n\u001b[32m      6\u001b[39m similarity = cosine_similarity_matrix(embs)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m similarity, traj\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36minfer\u001b[39m\u001b[34m(traj)\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(traj_embs, dim=\u001b[32m0\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minfer_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36minfer_batch\u001b[39m\u001b[34m(traj)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minfer_batch\u001b[39m(traj):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     traj_cell, traj_p = \u001b[38;5;28mzip\u001b[39m(*[merc2cell2(t, cellspace) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m traj])\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# print(traj_cell)\u001b[39;00m\n\u001b[32m     12\u001b[39m     traj_emb_p = [torch.tensor(generate_spatial_features(t, cellspace)) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m traj_p]\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "df_fil= df_part[df_part['traj_date'].isin([datetime.date(2025,3,28), datetime.date(2025,3,27)])]\n",
    "sim, traj = get_similarity(df_fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.79142416],\n",
       "       [0.79142416, 0.9999999 ]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[4501661.205581563, 4920809.243669961],\n",
       "  [4502628.720382543, 4907894.897599302],\n",
       "  [4495352.767144803, 4899518.644202666],\n",
       "  [4490913.6657944545, 4902065.6857565995],\n",
       "  [4492585.735668652, 4905780.798577032],\n",
       "  [4492443.153954195, 4911952.115215652],\n",
       "  [4495100.996064605, 4913308.941421218],\n",
       "  [4497705.319050238, 4915596.645665139],\n",
       "  [4498934.848408513, 4917068.726972317],\n",
       "  [4498965.594068378, 4919738.641298195],\n",
       "  [4500467.359702548, 4920911.797075757],\n",
       "  [4501727.620504184, 4921728.155148344],\n",
       "  [4501382.301696956, 4921276.8947026],\n",
       "  [4501390.557066074, 4920661.56838927],\n",
       "  [4500913.240005737, 4921531.239298347],\n",
       "  [4497710.394869184, 4921945.587025263],\n",
       "  [4498311.739197807, 4921888.151785998]],\n",
       " [[4500776.996192256, 4921408.16862271],\n",
       "  [4498033.472557481, 4921383.554647323],\n",
       "  [4497942.899564948, 4921867.639270812],\n",
       "  [4501382.642662631, 4921256.383289393],\n",
       "  [4501377.118241057, 4920641.058085184],\n",
       "  [4503706.222769652, 4918618.923573201],\n",
       "  [4500362.515295468, 4898994.564615704],\n",
       "  [4491567.337022878, 4901631.58386454],\n",
       "  [4490978.0027543735, 4901832.251556385],\n",
       "  [4490908.633326856, 4902094.353443475],\n",
       "  [4493740.029239463, 4908300.554415055],\n",
       "  [4495301.53260511, 4913308.941421218],\n",
       "  [4498508.915901022, 4915026.726554002],\n",
       "  [4499342.955204722, 4919927.322528156],\n",
       "  [4501663.315464359, 4921408.16862271]]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meters2lonlat(x, y):\n",
    "    semimajoraxis = 6378137.0\n",
    "    lon = x / semimajoraxis / 0.017453292519943295\n",
    "    t = math.exp(y / 3189068.5)\n",
    "    lat = math.asin((t - 1) / (t + 1)) / 0.017453292519943295\n",
    "    return (lon, lat)\n",
    "\n",
    "lon_lat_1 = [meters2lonlat(x,y) for x,y in traj[0]]\n",
    "lon_lat_2 = [meters2lonlat(x,y) for x,y in traj[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_lat_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_lat_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t = torch.tensor([[1,2,3],[3,4,5]])\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2500, 0.3333, 0.3750],\n",
       "        [0.7500, 0.6667, 0.6250]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t/t.sum(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trajcl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
