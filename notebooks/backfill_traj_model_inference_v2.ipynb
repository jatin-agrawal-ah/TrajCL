{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff741536-ea89-4225-a21d-f081e2871ac5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76597d19-5785-4483-9017-6a386d3e57f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import FloatType\n",
    "from config_infer import InferenceConfig\n",
    "from model.dual_attention import DualSTBTimeWeighted\n",
    "from utils.traj import *\n",
    "import pickle\n",
    "from utils.cellspace import *\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pyspark.sql.types import *\n",
    "# Global lazy init so it loads once per worker\n",
    "_model = None\n",
    "_device = None\n",
    "\n",
    "def _get_model():\n",
    "    global _model, _device\n",
    "    cfg = InferenceConfig()\n",
    "    if _model is None:\n",
    "        _device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        _model = DualSTBTimeWeighted(cfg.seq_embedding_dim, \n",
    "                                            cfg.trans_hidden_dim, \n",
    "                                            cfg.trans_attention_head, \n",
    "                                            cfg.trans_attention_layer, \n",
    "                                            cfg.trans_attention_dropout, \n",
    "                                            cfg.trans_pos_encoder_dropout)                 # define your model\n",
    "        checkpoint = torch.load(cfg.checkpoint_file, map_location=_device)['model_state_dict']\n",
    "        model_keys = [k for k in list(checkpoint.keys()) if 'encoder_q' in k]\n",
    "        new_checkpoint = {}\n",
    "        for k in model_keys:\n",
    "            new_k = k.replace('clmodel.encoder_q.', '')\n",
    "            new_checkpoint[new_k] = checkpoint[k]\n",
    "        _model.load_state_dict(new_checkpoint)\n",
    "        _model.to(_device).eval()\n",
    "    return _model, _device\n",
    "\n",
    "@pandas_udf(ArrayType(FloatType()))\n",
    "def predict_udf(traj: pd.Series, time_indices: pd.Series) -> pd.Series:\n",
    "    model, device = _get_model()\n",
    "    cfg = InferenceConfig()\n",
    "    embs_parent = pickle.load(open(cfg.dataset_embs_file_parent, 'rb')).to('cpu').detach() # tensor\n",
    "    embs_child = pickle.load(open(cfg.dataset_embs_file_child, 'rb')).to('cpu').detach() # tensor\n",
    "    cellspace_parent = pickle.load(open(cfg.dataset_cell_file_parent, 'rb'))\n",
    "    cellspace_child = pickle.load(open(cfg.dataset_cell_file_child, 'rb'))\n",
    "    hier_cellspace = HirearchicalCellSpace(cellspace_parent, cellspace_child)\n",
    "    with torch.no_grad():\n",
    "        # batch the column for efficiency\n",
    "        batches = []\n",
    "        bs = 32\n",
    "        for i in range(0, len(traj), bs):\n",
    "            traj_list = traj.iloc[i:i+bs].values.tolist()\n",
    "            time_indices_list = time_indices.iloc[i:i+bs].values.tolist()\n",
    "            time_indices_list = [np.array(time_indices_list[i], dtype='datetime64[ns]') for i in range(len(time_indices_list))]\n",
    "            # x = torch.tensor(traj.iloc[i:i+bs].values).float().to(device)\n",
    "            # y = model(x).squeeze().detach().cpu().numpy()\n",
    "            # batches.append(y)\n",
    "            traj_cell_parent, traj_cell_child, traj_p, traj_timedelta = zip(*[merc2cell2(l[:800],t[:800], hier_cellspace) for l,t in zip(traj_list, time_indices_list)])\n",
    "        # print(traj_cell)\n",
    "            traj_emb_p = [torch.tensor(generate_spatial_features(t, hier_cellspace)) for t in traj_p]\n",
    "            traj_emb_p = pad_sequence(traj_emb_p, batch_first = False).to(device)\n",
    "            traj_emb_cell_parent = [embs_parent[list(t)] for t in traj_cell_parent]\n",
    "            traj_emb_cell_child = [embs_child[list(t)] for t in traj_cell_child]\n",
    "            traj_emb_cell = [a + b for a, b in zip(traj_emb_cell_parent, traj_emb_cell_child)]\n",
    "            traj_emb_cell = pad_sequence(traj_emb_cell, batch_first = False).to(device)\n",
    "            traj_len = torch.tensor(list(map(len, traj_p)), dtype = torch.long, device = device)\n",
    "            traj_timedelta = pad_sequence([torch.tensor(t) for t in traj_timedelta], batch_first=False, padding_value=0).to(device)\n",
    "            max_traj_len = traj_len.max().item() # trajs1_len[0]\n",
    "            src_padding_mask = torch.arange(max_traj_len, device = device)[None, :] >= traj_len[:, None]\n",
    "            traj_embs = model(**{'src': traj_emb_cell, 'time_deltas': traj_timedelta, 'attn_mask': None, 'src_padding_mask': src_padding_mask, 'src_len': traj_len, 'srcspatial': traj_emb_p})\n",
    "            batches.append(traj_embs.detach().cpu().numpy())\n",
    "        return pd.Series(np.concatenate(batches).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27c0834a-fdb1-474f-a4e3-7515763349de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '/Volumes/main_prod/datascience_scratchpad/jatin/trajcl_exp/usa/backfill_traj_pre_data_rem_parquet'\n",
    "\n",
    "df = spark.read.parquet(data_dir)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd0b170b-a855-4f96-9e5f-01e9b794a5e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae3ad55e-3f49-4d41-9e09-c488f0a03cea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# limit to 100 samples\n",
    "# df = df.limit(1000000)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a2c71dc-176c-40b6-b814-088b24cd094e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50a91ee2-56e7-4fdd-a8fd-c0d2ce9493b9",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1759932667338}",
       "filterBlob": "{\"version\":1,\"filterGroups\":[],\"syncTimestamp\":1759938118589}",
       "queryPlanFiltersBlob": "[]",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# out_df = df.withColumn('embedding', predict_udf('merc_seq','sorted_ts'))\n",
    "# display(out_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccdc455c-4aa0-4248-9d26-c31cf229a43d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "out_df = df.withColumn('embedding', predict_udf('merc_seq','sorted_ts'))\n",
    "out_df.write.mode(\"overwrite\").parquet('/Volumes/main_prod/datascience_scratchpad/jatin/trajcl_exp/usa/backfill_rem_traj_emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6e9f080-51f7-4d91-872a-397deda7abdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"/Volumes/main_prod/datascience_scratchpad/jatin/trajcl_exp/usa/backfill_rem_traj_emb\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8595f6e7-95cb-4a0c-905a-543bb22acb79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# drop cols from df\n",
    "df = df.drop('merc_seq', 'sorted_ts', 'wgs_seq')\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "602f2519-ef4e-4ab6-84e5-b807435504cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create a new col with value as \"v1\"\n",
    "from pyspark.sql.functions import lit\n",
    "df = df.withColumn('model_version', lit('v1'))\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d500d071-317c-49d8-aca1-5fa5e644f2e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"traj_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e6c2ae4-5fc0-43d1-b3a5-1ab187c3970f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "MERGE INTO main_prod.datascience_scratchpad.traj_emb AS target\n",
    "USING traj_data AS source\n",
    "ON target.userid = source.userid\n",
    "   AND target.traj_date = source.traj_date\n",
    "WHEN MATCHED THEN \n",
    "  UPDATE SET *\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0d030ee-d9a7-4d5a-967f-ff625dbe9561",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df.write.mode(\"append\").saveAsTable(\"main_prod.datascience_scratchpad.traj_emb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21a866de-246f-40e5-b2e1-81717524ace3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.table(\"main_prod.datascience_scratchpad.traj_emb\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15f52143-bd9d-433f-8229-1c211d0446f1",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1760027073963}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# display(spark.sql(\"select * from main_prod.datascience_scratchpad.traj_emb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "704845e5-2e50-4f40-86af-d22974b090f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6195042780238434,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "backfill_traj_model_inference_v2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
