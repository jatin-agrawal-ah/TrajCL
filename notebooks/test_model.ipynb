{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../model\")\n",
    "from trajcl import TrajCL\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Config()\n",
    "\n",
    "conf.dataset = 'nyc'\n",
    "conf.post_value_updates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/.conda/envs/trajcl/lib/python3.12/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = TrajCL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrajCL(\n",
       "  (clmodel): MoCo(\n",
       "    (criterion): CrossEntropyLoss()\n",
       "    (encoder_q): DualSTBWithTime(\n",
       "      (pos_encoder): TimeBasedPosEncoding(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (structural_attn): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (spatial_attn): SpatialMSMWithTime(\n",
       "        (pos_encoder): TimeBasedPosEncoding(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (trans_encoder): SpatialMSMEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-2): 3 x SpatialMSMLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (norm1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_k): DualSTBWithTime(\n",
       "      (pos_encoder): TimeBasedPosEncoding(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (structural_attn): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (spatial_attn): SpatialMSMWithTime(\n",
       "        (pos_encoder): TimeBasedPosEncoding(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (trans_encoder): SpatialMSMEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-2): 3 x SpatialMSMLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (norm1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mlp_q): Projector(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (mlp_k): Projector(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.read_parquet(\"/home/sagemaker-user/TrajCL/data/parquet_files/test/nyc_df_v3_with_time/traj_test_df_v3_with_ts.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "userids = test_df['userid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12411/148144967.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrajCL(\n",
       "  (clmodel): MoCo(\n",
       "    (criterion): CrossEntropyLoss()\n",
       "    (encoder_q): DualSTBWithTime(\n",
       "      (pos_encoder): TimeBasedPosEncoding(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (structural_attn): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (spatial_attn): SpatialMSMWithTime(\n",
       "        (pos_encoder): TimeBasedPosEncoding(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (trans_encoder): SpatialMSMEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-2): 3 x SpatialMSMLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (norm1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_k): DualSTBWithTime(\n",
       "      (pos_encoder): TimeBasedPosEncoding(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (structural_attn): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (spatial_attn): SpatialMSMWithTime(\n",
       "        (pos_encoder): TimeBasedPosEncoding(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (trans_encoder): SpatialMSMEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-2): 3 x SpatialMSMLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (norm1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mlp_q): Projector(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (mlp_k): Projector(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\")\n",
    "checkpoint_file = \"/home/sagemaker-user/TrajCL/exp/v2.1/nyc_TrajCL_best.pt\"\n",
    "checkpoint = torch.load(checkpoint_file)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/.conda/envs/trajcl/lib/python3.12/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "from utils.traj import *\n",
    "import pickle\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "embs = pickle.load(open(\"/home/sagemaker-user/TrajCL/data/nyc_cell250_embdim256_embs.pkl\", 'rb')).to('cpu').detach() # tensor\n",
    "cellspace = pickle.load(open(\"/home/sagemaker-user/TrajCL/data/nyc_cell250_cellspace.pkl\", 'rb'))\n",
    "\n",
    "def infer(traj, time_indices):\n",
    "    traj_cell, traj_p = zip(*[merc2cell2(t, cellspace) for t in traj])\n",
    "    traj_emb_p = [torch.tensor(generate_spatial_features(t, cellspace)) for t in traj_p]\n",
    "    traj_emb_p = pad_sequence(traj_emb_p, batch_first = False).to(device)\n",
    "    traj_emb_cell = [embs[list(t)] for t in traj_cell]\n",
    "    traj_emb_cell = pad_sequence(traj_emb_cell, batch_first = False).to(device)\n",
    "    traj_len = torch.tensor(list(map(len, traj_cell)), dtype = torch.long, device = device)\n",
    "    time_indices = pad_sequence([torch.tensor(t, dtype=torch.long) for t in time_indices], batch_first=False, padding_value=-1).to(Config.device)\n",
    "    # print(traj_emb_cell, traj_emb_p, traj_len)\n",
    "    traj_embs = model.interpret(traj_emb_cell.float(), traj_emb_p.float(), traj_len, time_indices)\n",
    "    return traj_embs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>traj_id</th>\n",
       "      <th>timestamps_filtered</th>\n",
       "      <th>wgs_seq_filtered</th>\n",
       "      <th>merc_seq_filtered</th>\n",
       "      <th>trajlen</th>\n",
       "      <th>last_emp_start_date</th>\n",
       "      <th>traj_date</th>\n",
       "      <th>min_date</th>\n",
       "      <th>max_date</th>\n",
       "      <th>traj_count</th>\n",
       "      <th>last_pck_date</th>\n",
       "      <th>prev_pck_date</th>\n",
       "      <th>train_test_tag</th>\n",
       "      <th>paycheck_amount</th>\n",
       "      <th>label</th>\n",
       "      <th>time_index_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2908166</td>\n",
       "      <td>2908166_2023-07-10</td>\n",
       "      <td>[2023-07-10T05:58:48.000000, 2023-07-10T06:08:...</td>\n",
       "      <td>[[-74.13615838274143, 40.780548095703125], [-7...</td>\n",
       "      <td>[[-8252799.400536256, 4980026.246496455], [-82...</td>\n",
       "      <td>46</td>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>2025-07-23</td>\n",
       "      <td>1086</td>\n",
       "      <td>2025-07-25</td>\n",
       "      <td>2025-07-18</td>\n",
       "      <td>train</td>\n",
       "      <td>826</td>\n",
       "      <td>1</td>\n",
       "      <td>[35, 36, 38, 39, 40, 41, 43, 44, 45, 50, 51, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2908166</td>\n",
       "      <td>2908166_2024-04-17</td>\n",
       "      <td>[2024-04-17T05:27:52.000000, 2024-04-17T05:42:...</td>\n",
       "      <td>[[-74.13858887961788, 40.7818603515625], [-74....</td>\n",
       "      <td>[[-8253069.962210918, 4980219.164941694], [-82...</td>\n",
       "      <td>51</td>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>2025-07-23</td>\n",
       "      <td>1086</td>\n",
       "      <td>2025-07-25</td>\n",
       "      <td>2025-07-18</td>\n",
       "      <td>train</td>\n",
       "      <td>826</td>\n",
       "      <td>1</td>\n",
       "      <td>[32, 34, 38, 39, 40, 42, 44, 45, 46, 47, 48, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2908166</td>\n",
       "      <td>2908166_2024-12-29</td>\n",
       "      <td>[2024-12-29T04:37:54.000000, 2024-12-29T04:50:...</td>\n",
       "      <td>[[-74.13963465958288, 40.78245892193241], [-74...</td>\n",
       "      <td>[[-8253186.377904102, 4980307.163730451], [-82...</td>\n",
       "      <td>45</td>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>2025-07-23</td>\n",
       "      <td>1086</td>\n",
       "      <td>2025-07-25</td>\n",
       "      <td>2025-07-18</td>\n",
       "      <td>train</td>\n",
       "      <td>1318</td>\n",
       "      <td>1</td>\n",
       "      <td>[27, 29, 30, 31, 32, 36, 37, 38, 39, 40, 41, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2908166</td>\n",
       "      <td>2908166_2025-03-01</td>\n",
       "      <td>[2025-03-01T04:50:35.000000, 2025-03-01T09:54:...</td>\n",
       "      <td>[[-74.13176415310585, 40.77603776627111], [-74...</td>\n",
       "      <td>[[-8252310.237130794, 4979363.199270785], [-82...</td>\n",
       "      <td>55</td>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>2025-07-23</td>\n",
       "      <td>1086</td>\n",
       "      <td>2025-07-25</td>\n",
       "      <td>2025-07-18</td>\n",
       "      <td>train</td>\n",
       "      <td>839</td>\n",
       "      <td>1</td>\n",
       "      <td>[29, 59, 70, 75, 76, 77, 78, 79, 80, 81, 82, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2908166</td>\n",
       "      <td>2908166_2022-10-14</td>\n",
       "      <td>[2022-10-14T04:32:56.000000, 2022-10-14T04:45:...</td>\n",
       "      <td>[[-74.14570463447282, 40.78564453125], [-74.14...</td>\n",
       "      <td>[[-8253862.084417979, 4980775.509244509], [-82...</td>\n",
       "      <td>58</td>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>2022-10-14</td>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>2025-07-23</td>\n",
       "      <td>1086</td>\n",
       "      <td>2025-07-25</td>\n",
       "      <td>2025-07-18</td>\n",
       "      <td>train</td>\n",
       "      <td>826</td>\n",
       "      <td>1</td>\n",
       "      <td>[27, 28, 29, 30, 31, 32, 33, 35, 36, 38, 39, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userid             traj_id  \\\n",
       "0  2908166  2908166_2023-07-10   \n",
       "1  2908166  2908166_2024-04-17   \n",
       "2  2908166  2908166_2024-12-29   \n",
       "3  2908166  2908166_2025-03-01   \n",
       "4  2908166  2908166_2022-10-14   \n",
       "\n",
       "                                 timestamps_filtered  \\\n",
       "0  [2023-07-10T05:58:48.000000, 2023-07-10T06:08:...   \n",
       "1  [2024-04-17T05:27:52.000000, 2024-04-17T05:42:...   \n",
       "2  [2024-12-29T04:37:54.000000, 2024-12-29T04:50:...   \n",
       "3  [2025-03-01T04:50:35.000000, 2025-03-01T09:54:...   \n",
       "4  [2022-10-14T04:32:56.000000, 2022-10-14T04:45:...   \n",
       "\n",
       "                                    wgs_seq_filtered  \\\n",
       "0  [[-74.13615838274143, 40.780548095703125], [-7...   \n",
       "1  [[-74.13858887961788, 40.7818603515625], [-74....   \n",
       "2  [[-74.13963465958288, 40.78245892193241], [-74...   \n",
       "3  [[-74.13176415310585, 40.77603776627111], [-74...   \n",
       "4  [[-74.14570463447282, 40.78564453125], [-74.14...   \n",
       "\n",
       "                                   merc_seq_filtered  trajlen  \\\n",
       "0  [[-8252799.400536256, 4980026.246496455], [-82...       46   \n",
       "1  [[-8253069.962210918, 4980219.164941694], [-82...       51   \n",
       "2  [[-8253186.377904102, 4980307.163730451], [-82...       45   \n",
       "3  [[-8252310.237130794, 4979363.199270785], [-82...       55   \n",
       "4  [[-8253862.084417979, 4980775.509244509], [-82...       58   \n",
       "\n",
       "  last_emp_start_date   traj_date    min_date    max_date  traj_count  \\\n",
       "0          2021-07-23  2023-07-10  2021-07-23  2025-07-23        1086   \n",
       "1          2021-07-23  2024-04-17  2021-07-23  2025-07-23        1086   \n",
       "2          2021-07-23  2024-12-29  2021-07-23  2025-07-23        1086   \n",
       "3          2021-07-23  2025-03-01  2021-07-23  2025-07-23        1086   \n",
       "4          2021-07-23  2022-10-14  2021-07-23  2025-07-23        1086   \n",
       "\n",
       "  last_pck_date prev_pck_date train_test_tag  paycheck_amount  label  \\\n",
       "0    2025-07-25    2025-07-18          train              826      1   \n",
       "1    2025-07-25    2025-07-18          train              826      1   \n",
       "2    2025-07-25    2025-07-18          train             1318      1   \n",
       "3    2025-07-25    2025-07-18          train              839      1   \n",
       "4    2025-07-25    2025-07-18          train              826      1   \n",
       "\n",
       "                                     time_index_list  \n",
       "0  [35, 36, 38, 39, 40, 41, 43, 44, 45, 50, 51, 5...  \n",
       "1  [32, 34, 38, 39, 40, 42, 44, 45, 46, 47, 48, 5...  \n",
       "2  [27, 29, 30, 31, 32, 36, 37, 38, 39, 40, 41, 4...  \n",
       "3  [29, 59, 70, 75, 76, 77, 78, 79, 80, 81, 82, 8...  \n",
       "4  [27, 28, 29, 30, 31, 32, 33, 35, 36, 38, 39, 4...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 35,  36,  38,  39,  40,  41,  43,  44,  45,  50,  51,  52,  53,\n",
       "        55,  56,  58,  59,  60,  80,  85,  86,  87,  88,  90,  91,  92,\n",
       "        93,  94,  95,  97,  98, 100, 101, 105, 106, 107, 109, 110, 111,\n",
       "       113, 114, 115, 116, 118, 119, 120], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['time_index_list'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "model.eval()\n",
    "gt_list = []\n",
    "pred_list = []\n",
    "def get_gt_and_pred_label(userid):\n",
    "    user_data = test_df[test_df['userid'] == userid].reset_index(drop=True)\n",
    "    train_data = user_data[user_data['train_test_tag'] == 'train'].reset_index(drop=True)\n",
    "    test_data = user_data[user_data['train_test_tag'] == 'test'].reset_index(drop=True)\n",
    "    train_traj = train_data['merc_seq_filtered'].values\n",
    "    test_traj = test_data['merc_seq_filtered'].values\n",
    "    train_time_indices = train_data['time_index_list'].values\n",
    "    test_time_indices = test_data['time_index_list'].values\n",
    "    train_embs = infer(train_traj, train_time_indices).detach().cpu().numpy()\n",
    "    test_embs = infer(test_traj, test_time_indices).detach().cpu()\n",
    "    if sum(test_data['paycheck_amount'].values) > 0:\n",
    "        gt_label = 1\n",
    "    else:\n",
    "        gt_label = 0\n",
    "    pred_label = 0\n",
    "    for i in range(len(test_embs)):\n",
    "        test_vector = test_embs[i].unsqueeze(0)\n",
    "        similarity = cosine_similarity(test_vector.numpy(), train_embs)[0]\n",
    "        top_3_indices = np.argsort(similarity)[-3:][::-1]\n",
    "        # print(i, top_3_indices)\n",
    "        similarity = similarity[top_3_indices]\n",
    "        # print(f\"User: {userid}, Test Trajectory {test_data['traj_id'].values[i]}, Top 3 Train Trajectories: {train_data['traj_id'].values[top_3_indices]}, similarity: {similarity}, PCK Amount: {train_data['paycheck_amount'].values[top_3_indices]}\")\n",
    "        for sim, idx in zip(similarity, top_3_indices):\n",
    "            if sim>0.85 and train_data['paycheck_amount'].values[idx]>0:\n",
    "                pred_label = 1\n",
    "                break\n",
    "    return gt_label, pred_label\n",
    "\n",
    "for userid in tqdm(userids):\n",
    "    gt_label, pred_label = get_gt_and_pred_label(userid)\n",
    "    gt_list.append(gt_label)\n",
    "    pred_list.append(pred_label)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of 0 labels\n",
    "sum(gt_list) / len(gt_list), sum(pred_list) / len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(gt_list, pred_list)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(gt_list, pred_list)\n",
    "# Assuming you already have the confusion matrix 'cm'\n",
    "# For binary classification, cm is in the form:\n",
    "# [[TN, FP],\n",
    "#  [FN, TP]]\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"True Positives:\", tp)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"True Negatives:\", tn)\n",
    "print(\"False Negatives:\", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = precision_score(gt_list, pred_list)\n",
    "recall = recall_score(gt_list, pred_list)\n",
    "f1 = f1_score(gt_list, pred_list)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gt_and_pred_label(userid):\n",
    "    user_data = test_df[test_df['userid'] == userid].reset_index(drop=True)\n",
    "    train_data = user_data[user_data['train_test_tag'] == 'train'].reset_index(drop=True)\n",
    "    test_data = user_data[user_data['train_test_tag'] == 'test'].reset_index(drop=True)\n",
    "    train_traj = train_data['merc_seq_filtered'].values\n",
    "    test_traj = test_data['merc_seq_filtered'].values\n",
    "    train_embs = infer(train_traj).detach().cpu().numpy()\n",
    "    test_embs = infer(test_traj).detach().cpu()\n",
    "    if sum(test_data['paycheck_amount'].values) > 0:\n",
    "        gt_label = 1\n",
    "    else:\n",
    "        gt_label = 0\n",
    "    pred_label = 0\n",
    "    for i in range(len(test_embs)):\n",
    "        test_vector = test_embs[i].unsqueeze(0)\n",
    "        similarity = cosine_similarity(test_vector.numpy(), train_embs)[0]\n",
    "        top_3_indices = np.argsort(similarity)[-3:][::-1]\n",
    "        # print(i, top_3_indices)\n",
    "        similarity = similarity[top_3_indices]\n",
    "        print(f\"User: {userid}, Test Trajectory {test_data['traj_id'].values[i]}, Top 3 Train Trajectories: {train_data['traj_id'].values[top_3_indices]}, similarity: {similarity}, PCK Amount: {train_data['paycheck_amount'].values[top_3_indices]}\")\n",
    "        for sim, idx in zip(similarity, top_3_indices):\n",
    "            if sim>0.85 and train_data['paycheck_amount'].values[idx]>0:\n",
    "                pred_label = 1\n",
    "                break\n",
    "    return gt_label, pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_indices = [i for i, (gt, pred) in enumerate(zip(gt_list, pred_list)) if gt == pred]\n",
    "print(\"Correct Indices:\", correct_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_indices = [i for i, (gt, pred) in enumerate(zip(gt_list, pred_list)) if gt == 1 and pred == 0]\n",
    "print(\"False Negative Indices:\", fn_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_indices = [i for i, (gt, pred) in enumerate(zip(gt_list, pred_list)) if gt == 0 and pred == 1]\n",
    "print(\"False Positive Indices:\", fp_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "userid = userids[idx]\n",
    "get_gt_and_pred_label(userid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_df[test_df['train_test_tag'] == 'test'][test_df['label']==1]['userid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "790/1051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df['userid']==5499415].sort_values('traj_date',ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trajcl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
