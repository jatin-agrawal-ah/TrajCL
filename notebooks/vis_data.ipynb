{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = \"/home/sagemaker-user/TrajCL/data/porto_20200\"\n",
    "trajs = pd.read_pickle(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset\n",
    "# class TrajDataset(Dataset):\n",
    "#     def __init__(self, data):\n",
    "#         # data: DataFrame\n",
    "#         self.data = data\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return self.data.loc[index].merc_seq\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = trajs.shape[0]\n",
    "# train_idx = (int(l*0), 200000)\n",
    "# eval_idx = (int(l*0.7), int(l*0.8))\n",
    "# test_idx = (int(l*0.8), int(l*1.0))\n",
    "\n",
    "# train = TrajDataset(trajs[train_idx[0]: train_idx[1]])\n",
    "# eval = TrajDataset(trajs[eval_idx[0]: eval_idx[1]])\n",
    "# test = TrajDataset(trajs[test_idx[0]: test_idx[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 15\n",
    "lon_lat_list = trajs['wgs_seq'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_lat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install folium\n",
    "import folium\n",
    "\n",
    "from folium import plugins\n",
    "coordinates = [[x[0],x[1]] for x in lon_lat_list]\n",
    "# Initialize map\n",
    "m = folium.Map(location=coordinates[0], zoom_start=30)\n",
    "\n",
    "folium.Marker(\n",
    "    location=coordinates[0],\n",
    "    popup=\"Start Location\",\n",
    "    icon=folium.Icon(color='green')  # Color can be 'red', 'blue', 'green', 'purple', etc.\n",
    ").add_to(m)\n",
    "# Add markers\n",
    "for lat, lon in coordinates[1:]:\n",
    "    folium.Marker([lat, lon]).add_to(m)\n",
    "\n",
    "# Draw arrows between points\n",
    "for i in range(len(coordinates) - 1):\n",
    "    start = coordinates[i]\n",
    "    end = coordinates[i + 1]\n",
    "\n",
    "    # Draw the line\n",
    "    line = folium.PolyLine([start, end], color=\"blue\", weight=3, opacity=0.7).add_to(m)\n",
    "\n",
    "    # Add directional arrow\n",
    "    plugins.PolyLineTextPath(\n",
    "        line,\n",
    "        'âž¤',  # arrow symbol\n",
    "        repeat=True,\n",
    "        offset=7,\n",
    "        attributes={'fill': 'blue', 'font-weight': 'bold', 'font-size': '16'}\n",
    "    ).add_to(m)\n",
    "\n",
    "# Save and show the map\n",
    "m.save(\"map_with_arrows.html\")\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.cellspace import CellSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "porto_cs = pickle.load(open(\"/home/sagemaker-user/TrajCL/data/porto_20200_cell100_cellspace.pkl\",\"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porto_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porto_cs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_lat_list = [[-8.660646, 41.168574],\n",
    " [-8.661087, 41.167926],\n",
    " [-8.661231, 41.166576],\n",
    " [-8.660637, 41.166396],\n",
    " [-8.660295, 41.166819],\n",
    " [-8.658954, 41.168394],\n",
    " [-8.657649, 41.169906],\n",
    " [-8.656371, 41.171454],\n",
    " [-8.654706, 41.173479],\n",
    " [-8.653014, 41.17527],\n",
    " [-8.651349, 41.17644],\n",
    " [-8.652213, 41.177241],\n",
    " [-8.651358, 41.178069],\n",
    " [-8.65071, 41.178924],\n",
    " [-8.65125, 41.17968],\n",
    " [-8.649648, 41.180643],\n",
    " [-8.647515, 41.18193],\n",
    " [-8.644491, 41.183541],\n",
    " [-8.641701, 41.184108],\n",
    " [-8.638677, 41.182452],\n",
    " [-8.635284, 41.180589],\n",
    " [-8.632476, 41.179104],\n",
    " [-8.629983, 41.179365],\n",
    " [-8.629857, 41.179374],\n",
    " [-8.629857, 41.179374],\n",
    " [-8.629263, 41.179437],\n",
    " [-8.625996, 41.179779],\n",
    " [-8.622018, 41.180463],\n",
    " [-8.61885, 41.181912],\n",
    " [-8.617077, 41.182821],\n",
    " [-8.614215, 41.183082],\n",
    " [-8.613675, 41.183136],\n",
    " [-8.613702, 41.183145],\n",
    " [-8.613288, 41.18319],\n",
    " [-8.610813, 41.184],\n",
    " [-8.607474, 41.184648],\n",
    " [-8.604018, 41.183892],\n",
    " [-8.601768, 41.183253],\n",
    " [-8.601588, 41.182632],\n",
    " [-8.601957, 41.181831],\n",
    " [-8.601903, 41.181795],\n",
    " [-8.601948, 41.181822],\n",
    " [-8.601894, 41.181813]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porto_cs.x_min, porto_cs.x_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tool_funcs import lonlat2meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonlat2meters(lon_lat_list[0][0],lon_lat_list[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_ids = [porto_cs.get_cellid_by_point(*lonlat2meters(x[0],x[1])) for x in lon_lat_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ah_databricks_data_loader import DatabricksDataLoader\n",
    "\n",
    "# Instantiate the DatabricksDataLoader.\n",
    "ddl = DatabricksDataLoader()\n",
    "\n",
    "# List available shares.\n",
    "shares = ddl.list_shares()\n",
    "\n",
    "# Print shares.\n",
    "print(shares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9069952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ah_databricks_data_loader import DatabricksDataLoader\n",
    "\n",
    "# Instantiate the DatabricksDataLoader.\n",
    "ddl = DatabricksDataLoader()\n",
    "\n",
    "# Load data.\n",
    "df = ddl.load_as_spark(schema=\"datascience_scratchpad\", table=\"all_traj_val\")\n",
    "\n",
    "# Display the loaded DataFrame.\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for row in df.toLocalIterator():\n",
    "    print(row)\n",
    "    count+=1\n",
    "    if count>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row['traj_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = df.randomSplit([0.8, 0.1, 0.1], seed=42)  # seed for reproducibility\n",
    "train_df, val_df, test_df = splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_index = df.rdd.zipWithIndex().map(lambda x: (x[1], x[0])).toDF([\"row_index\", \"row\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_index.filter(df_with_index['row_index']==2).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(df.toLocalIterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(10).write.parquet(\"/mnt/sagemaker-nvme/data/usa/val\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = \"/home/sagemaker-user/TrajCL/data/nyc/train_with_ts/\"\n",
    "files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(\".parquet\")]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "total_count = 0\n",
    "for file_path in tqdm(files):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    total_count+=len(df)\n",
    "\n",
    "total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet(\"/home/sagemaker-user/TrajCL/data/parquet_files/nyc_v2/part-00000-76372e3b-95b4-498e-9e85-2765482fcef5-c000.snappy.parquet\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.stack(test['merc_seq_filtered'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "class ParquetDataset(IterableDataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(\".parquet\")]\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file_path in self.files:\n",
    "            df = pd.read_parquet(file_path)\n",
    "            features = df[\"merc_seq_filtered\"].values\n",
    "            for feature in features:\n",
    "                yield torch.tensor(np.stack(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_dataset = ParquetDataset(\"/home/sagemaker-user/TrajCL/data/parquet_files/nyc/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dl = DataLoader(parquet_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for batch in dl:\n",
    "    print(batch)\n",
    "    count+=1\n",
    "    if count>10:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trajcl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
